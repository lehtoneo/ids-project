{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21bf97b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile # to read audio file\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa # to extract speech features\n",
    "import glob\n",
    "import os\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model, to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "077c8742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name, **kwargs):\n",
    "    \"\"\"\n",
    "    Extract feature from audio file `file_name`\n",
    "        Features supported:\n",
    "            - MFCC (mfcc)\n",
    "            - Chroma (chroma)\n",
    "            - MEL Spectrogram Frequency (mel)\n",
    "            - Contrast (contrast)\n",
    "            - Tonnetz (tonnetz)\n",
    "        e.g:\n",
    "        `features = extract_feature(path, mel=True, mfcc=True)`\n",
    "    \"\"\"\n",
    "    mfcc = kwargs.get(\"mfcc\")\n",
    "    chroma = kwargs.get(\"chroma\")\n",
    "    mel = kwargs.get(\"mel\")\n",
    "    contrast = kwargs.get(\"contrast\")\n",
    "    tonnetz = kwargs.get(\"tonnetz\")\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        if (len(X.shape) != 1):\n",
    "            if (X.shape[1] == 2):\n",
    "                X = X[:,0]\n",
    "            else:\n",
    "                return [None]\n",
    "        sample_rate = sound_file.samplerate\n",
    "        if chroma or contrast:\n",
    "            stft = np.abs(librosa.stft(X))\n",
    "        result = np.array([])\n",
    "        if mfcc:\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, mel))\n",
    "        if contrast:\n",
    "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, contrast))\n",
    "        if tonnetz:\n",
    "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, tonnetz))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "350d3565",
   "metadata": {},
   "outputs": [],
   "source": [
    "## codes in data\n",
    "int2emotion = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n",
    "\n",
    "# only files with these emotion labels are used\n",
    "emotions_dict ={\n",
    "    \"neutral\": 0,\n",
    "    \"happy\": 1,\n",
    "    \"angry\": 2,\n",
    "    \"surprised\": 3\n",
    "}\n",
    "\n",
    "category_to_emotion = {}\n",
    "\n",
    "for key in emotions_dict.keys():\n",
    "    value = emotions_dict[key]\n",
    "    category_to_emotion[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "edf12b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(test_size=0.2, max_amount=10000):\n",
    "    i = 0\n",
    "    X, y = [], []\n",
    "    amount = 0\n",
    "    for file in glob.glob(\"ravdess/Audio*/Actor_*/*.wav\"):\n",
    "        if (amount >= max_amount):\n",
    "            break\n",
    "        \n",
    "        basename = os.path.basename(file)\n",
    "        \n",
    "        emotion = int2emotion[basename.split(\"-\")[2]]\n",
    "        allowed_emotions = emotions_dict.keys()\n",
    "        \n",
    "        if emotion not in allowed_emotions:\n",
    "            continue\n",
    "        emotion_category = emotions_dict[emotion]\n",
    "        \n",
    "        features = extract_feature(file, mfcc=True, mel=True)\n",
    "        \n",
    "        ## there seems to be some unusable data so lets get rid of those\n",
    "        if (features[0] == None):\n",
    "            continue\n",
    "        \n",
    "        \n",
    "            \n",
    "        X.append(features)\n",
    "        y.append(emotion_category)\n",
    "        amount = amount + 1\n",
    "        \n",
    "    return train_test_split(np.array(X), y, test_size=test_size, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fb1ea6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_amount_of_data = 100000\n",
    "X_train, X_test, y_train, y_test = load_data(test_size=0.25, max_amount=max_amount_of_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "017cc9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "\n",
    "y_train = np.asarray(y_train)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = np.asarray(y_test)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "nb_classes = len(emotions_dict.keys())\n",
    "y_train = to_categorical(y_train, nb_classes)\n",
    "y_test = to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5e286848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Number of training samples: 504\n",
      "[+] Train shape (504, 168)\n",
      "[+] Number of testing samples: 168\n",
      "[+] Number of features: 168\n"
     ]
    }
   ],
   "source": [
    "print(\"[+] Number of training samples:\", X_train.shape[0])\n",
    "print(\"[+] Train shape\", X_train.shape)\n",
    "# number of samples in testing data\n",
    "print(\"[+] Number of testing samples:\", X_test.shape[0])\n",
    "# number of features used\n",
    "# this is a vector of features extracted \n",
    "# using extract_features() function\n",
    "print(\"[+] Number of features:\", X_train.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6fe4ae70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] X_train first value's first 5 values [-429.91245    47.63481   -19.548073    7.647203  -11.776189]\n",
      "[+] y_train first value [0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"[+] X_train first value's first 5 values\", X_train[0][0:5])\n",
    "print(\"[+] y_train first value\", y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a90e789",
   "metadata": {},
   "source": [
    "# Data for pitch session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da1e141",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b677a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn = np.expand_dims(X_train, axis=2)\n",
    "x_testcnn = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981f0385",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a7f117da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 168, 128)          768       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 168, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 168, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 10756     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 93,572\n",
      "Trainable params: 93,572\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "8/8 [==============================] - 1s 37ms/step - loss: 4.6400 - accuracy: 0.2877 - val_loss: 1.7943 - val_accuracy: 0.2619\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 3.7438 - accuracy: 0.2718 - val_loss: 1.4617 - val_accuracy: 0.2976\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 3.6885 - accuracy: 0.2817 - val_loss: 1.5086 - val_accuracy: 0.2798\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 3.3526 - accuracy: 0.3393 - val_loss: 1.5221 - val_accuracy: 0.2738\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.4047 - accuracy: 0.3095 - val_loss: 1.6328 - val_accuracy: 0.3095\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.3261 - accuracy: 0.2976 - val_loss: 1.2693 - val_accuracy: 0.5119\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 3.1416 - accuracy: 0.3036 - val_loss: 1.3059 - val_accuracy: 0.3393\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.2538 - accuracy: 0.3214 - val_loss: 1.5613 - val_accuracy: 0.2798\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 3.1797 - accuracy: 0.3175 - val_loss: 1.5818 - val_accuracy: 0.3452\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.9364 - accuracy: 0.3393 - val_loss: 1.2617 - val_accuracy: 0.4286\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.0131 - accuracy: 0.3373 - val_loss: 1.3971 - val_accuracy: 0.3214\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.8517 - accuracy: 0.3194 - val_loss: 1.3018 - val_accuracy: 0.4167\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.8669 - accuracy: 0.3294 - val_loss: 1.2876 - val_accuracy: 0.3929\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.8689 - accuracy: 0.3016 - val_loss: 1.4349 - val_accuracy: 0.3214\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.6119 - accuracy: 0.3909 - val_loss: 1.3149 - val_accuracy: 0.3155\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.7894 - accuracy: 0.3611 - val_loss: 1.2675 - val_accuracy: 0.3810\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.7832 - accuracy: 0.3254 - val_loss: 1.3056 - val_accuracy: 0.2798\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.4682 - accuracy: 0.3591 - val_loss: 1.1794 - val_accuracy: 0.5417\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.5164 - accuracy: 0.3512 - val_loss: 1.2400 - val_accuracy: 0.3988\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.4064 - accuracy: 0.3849 - val_loss: 1.2390 - val_accuracy: 0.4286\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.4089 - accuracy: 0.3631 - val_loss: 1.3585 - val_accuracy: 0.3155\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.2999 - accuracy: 0.3571 - val_loss: 1.3626 - val_accuracy: 0.3333\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.3989 - accuracy: 0.3393 - val_loss: 1.1580 - val_accuracy: 0.4940\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.2101 - accuracy: 0.3889 - val_loss: 1.1841 - val_accuracy: 0.4762\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.1459 - accuracy: 0.3909 - val_loss: 1.3452 - val_accuracy: 0.3452\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.1049 - accuracy: 0.3750 - val_loss: 1.2180 - val_accuracy: 0.4048\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0591 - accuracy: 0.3988 - val_loss: 1.1509 - val_accuracy: 0.5417\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.2106 - accuracy: 0.3710 - val_loss: 1.2267 - val_accuracy: 0.3869\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.1701 - accuracy: 0.3671 - val_loss: 1.1839 - val_accuracy: 0.4940\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.9820 - accuracy: 0.3829 - val_loss: 1.1726 - val_accuracy: 0.4821\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.1163 - accuracy: 0.3869 - val_loss: 1.2101 - val_accuracy: 0.3988\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.9471 - accuracy: 0.3869 - val_loss: 1.1294 - val_accuracy: 0.5536\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.9470 - accuracy: 0.3968 - val_loss: 1.2390 - val_accuracy: 0.4464\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.9644 - accuracy: 0.3829 - val_loss: 1.2746 - val_accuracy: 0.3274\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.8984 - accuracy: 0.3849 - val_loss: 1.1177 - val_accuracy: 0.5357\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.8645 - accuracy: 0.3849 - val_loss: 1.1761 - val_accuracy: 0.4821\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.8330 - accuracy: 0.3948 - val_loss: 1.1693 - val_accuracy: 0.4762\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.8881 - accuracy: 0.3909 - val_loss: 1.1564 - val_accuracy: 0.5238\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.7567 - accuracy: 0.4226 - val_loss: 1.1485 - val_accuracy: 0.5060\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.8364 - accuracy: 0.3869 - val_loss: 1.2267 - val_accuracy: 0.4821\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.7105 - accuracy: 0.4028 - val_loss: 1.1293 - val_accuracy: 0.5417\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.6852 - accuracy: 0.4206 - val_loss: 1.1024 - val_accuracy: 0.5476\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7428 - accuracy: 0.4028 - val_loss: 1.2534 - val_accuracy: 0.3690\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.7889 - accuracy: 0.3988 - val_loss: 1.1292 - val_accuracy: 0.5357\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.6302 - accuracy: 0.4286 - val_loss: 1.1980 - val_accuracy: 0.4107\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.6145 - accuracy: 0.4306 - val_loss: 1.2017 - val_accuracy: 0.3988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.5892 - accuracy: 0.4067 - val_loss: 1.1281 - val_accuracy: 0.5298\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.5117 - accuracy: 0.4147 - val_loss: 1.1639 - val_accuracy: 0.4583\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.4852 - accuracy: 0.4048 - val_loss: 1.1376 - val_accuracy: 0.5595\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.6132 - accuracy: 0.3968 - val_loss: 1.0855 - val_accuracy: 0.5893\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.5014 - accuracy: 0.3968 - val_loss: 1.0919 - val_accuracy: 0.5417\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5438 - accuracy: 0.4226 - val_loss: 1.1016 - val_accuracy: 0.5357\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.4352 - accuracy: 0.4524 - val_loss: 1.1073 - val_accuracy: 0.5298\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.4360 - accuracy: 0.4325 - val_loss: 1.1829 - val_accuracy: 0.4167\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.4848 - accuracy: 0.3948 - val_loss: 1.2112 - val_accuracy: 0.4226\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3763 - accuracy: 0.4048 - val_loss: 1.1435 - val_accuracy: 0.4464\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.4229 - accuracy: 0.4226 - val_loss: 1.1101 - val_accuracy: 0.5298\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.4109 - accuracy: 0.4306 - val_loss: 1.1339 - val_accuracy: 0.4821\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.4456 - accuracy: 0.4266 - val_loss: 1.1160 - val_accuracy: 0.5000\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.4019 - accuracy: 0.4306 - val_loss: 1.1491 - val_accuracy: 0.4345\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3925 - accuracy: 0.4067 - val_loss: 1.1488 - val_accuracy: 0.4405\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.3821 - accuracy: 0.4464 - val_loss: 1.0943 - val_accuracy: 0.5119\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.4184 - accuracy: 0.4504 - val_loss: 1.0687 - val_accuracy: 0.5833\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.3548 - accuracy: 0.4623 - val_loss: 1.1083 - val_accuracy: 0.5000\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2790 - accuracy: 0.4702 - val_loss: 1.1366 - val_accuracy: 0.4405\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.3589 - accuracy: 0.4365 - val_loss: 1.1339 - val_accuracy: 0.4821\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2490 - accuracy: 0.4722 - val_loss: 1.0925 - val_accuracy: 0.5000\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.2788 - accuracy: 0.4444 - val_loss: 1.0662 - val_accuracy: 0.5774\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.3349 - accuracy: 0.4464 - val_loss: 1.0666 - val_accuracy: 0.5357\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.2935 - accuracy: 0.4345 - val_loss: 1.2150 - val_accuracy: 0.3810\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.2666 - accuracy: 0.4643 - val_loss: 1.1192 - val_accuracy: 0.4405\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3009 - accuracy: 0.4325 - val_loss: 1.0506 - val_accuracy: 0.5536\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.2557 - accuracy: 0.4643 - val_loss: 1.0771 - val_accuracy: 0.5595\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.2370 - accuracy: 0.4544 - val_loss: 1.0649 - val_accuracy: 0.5774\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.1783 - accuracy: 0.4921 - val_loss: 1.0644 - val_accuracy: 0.5952\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.2104 - accuracy: 0.4623 - val_loss: 1.1153 - val_accuracy: 0.5060\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.2128 - accuracy: 0.4583 - val_loss: 1.0506 - val_accuracy: 0.5655\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.1770 - accuracy: 0.4881 - val_loss: 1.0629 - val_accuracy: 0.5298\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.1857 - accuracy: 0.4940 - val_loss: 1.1423 - val_accuracy: 0.4643\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.2378 - accuracy: 0.4603 - val_loss: 1.1193 - val_accuracy: 0.4583\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.1670 - accuracy: 0.4841 - val_loss: 1.0794 - val_accuracy: 0.5179\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.1971 - accuracy: 0.4782 - val_loss: 1.1041 - val_accuracy: 0.5000\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.1846 - accuracy: 0.4762 - val_loss: 1.0429 - val_accuracy: 0.5833\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.1876 - accuracy: 0.4722 - val_loss: 1.0399 - val_accuracy: 0.5536\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.1494 - accuracy: 0.5000 - val_loss: 1.0556 - val_accuracy: 0.5536\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.2011 - accuracy: 0.4782 - val_loss: 1.1050 - val_accuracy: 0.4940\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1413 - accuracy: 0.4861 - val_loss: 1.0592 - val_accuracy: 0.5357\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.1665 - accuracy: 0.4722 - val_loss: 1.0907 - val_accuracy: 0.4940\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.1326 - accuracy: 0.4901 - val_loss: 1.0500 - val_accuracy: 0.5476\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.1845 - accuracy: 0.4504 - val_loss: 1.0744 - val_accuracy: 0.5238\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.0887 - accuracy: 0.5079 - val_loss: 1.0634 - val_accuracy: 0.5476\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1563 - accuracy: 0.4742 - val_loss: 1.0568 - val_accuracy: 0.5179\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.1202 - accuracy: 0.4603 - val_loss: 1.0508 - val_accuracy: 0.5238\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1600 - accuracy: 0.4663 - val_loss: 1.0537 - val_accuracy: 0.5179\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.1087 - accuracy: 0.5238 - val_loss: 1.0475 - val_accuracy: 0.5536\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.1377 - accuracy: 0.5139 - val_loss: 1.0438 - val_accuracy: 0.6012\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0786 - accuracy: 0.5317 - val_loss: 1.0754 - val_accuracy: 0.5060\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.1280 - accuracy: 0.4901 - val_loss: 1.0406 - val_accuracy: 0.6012\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0993 - accuracy: 0.4802 - val_loss: 1.0753 - val_accuracy: 0.5357\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0963 - accuracy: 0.4940 - val_loss: 1.0996 - val_accuracy: 0.5119\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.1266 - accuracy: 0.4980 - val_loss: 1.0789 - val_accuracy: 0.5238\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.1315 - accuracy: 0.4841 - val_loss: 1.0587 - val_accuracy: 0.5476\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0970 - accuracy: 0.4921 - val_loss: 1.0459 - val_accuracy: 0.5595\n",
      "Epoch 104/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 1.1038 - accuracy: 0.4881 - val_loss: 1.0652 - val_accuracy: 0.5357\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0920 - accuracy: 0.5218 - val_loss: 1.0488 - val_accuracy: 0.5714\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0919 - accuracy: 0.5079 - val_loss: 1.0833 - val_accuracy: 0.5238\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0736 - accuracy: 0.5496 - val_loss: 1.0518 - val_accuracy: 0.5833\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0610 - accuracy: 0.5238 - val_loss: 1.0870 - val_accuracy: 0.4821\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.0706 - accuracy: 0.5079 - val_loss: 1.0670 - val_accuracy: 0.5417\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.0693 - accuracy: 0.5377 - val_loss: 1.0439 - val_accuracy: 0.5833\n",
      "Epoch 111/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0899 - accuracy: 0.5218 - val_loss: 1.0549 - val_accuracy: 0.5833\n",
      "Epoch 112/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0484 - accuracy: 0.5020 - val_loss: 1.0325 - val_accuracy: 0.5714\n",
      "Epoch 113/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0275 - accuracy: 0.5218 - val_loss: 1.1022 - val_accuracy: 0.4643\n",
      "Epoch 114/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.0574 - accuracy: 0.5139 - val_loss: 1.0599 - val_accuracy: 0.5595\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0250 - accuracy: 0.5317 - val_loss: 1.0452 - val_accuracy: 0.5536\n",
      "Epoch 116/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0599 - accuracy: 0.5020 - val_loss: 1.0786 - val_accuracy: 0.4821\n",
      "Epoch 117/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0495 - accuracy: 0.5159 - val_loss: 1.0402 - val_accuracy: 0.5536\n",
      "Epoch 118/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.0602 - accuracy: 0.5198 - val_loss: 1.0302 - val_accuracy: 0.5893\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0406 - accuracy: 0.5179 - val_loss: 1.0316 - val_accuracy: 0.5774\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0237 - accuracy: 0.5218 - val_loss: 1.0532 - val_accuracy: 0.5536\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0430 - accuracy: 0.5357 - val_loss: 1.0098 - val_accuracy: 0.6071\n",
      "Epoch 122/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0266 - accuracy: 0.5198 - val_loss: 1.0523 - val_accuracy: 0.5476\n",
      "Epoch 123/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0287 - accuracy: 0.5397 - val_loss: 1.0100 - val_accuracy: 0.5952\n",
      "Epoch 124/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0412 - accuracy: 0.5218 - val_loss: 1.0125 - val_accuracy: 0.6071\n",
      "Epoch 125/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0172 - accuracy: 0.5218 - val_loss: 1.0300 - val_accuracy: 0.5952\n",
      "Epoch 126/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0401 - accuracy: 0.5179 - val_loss: 1.0280 - val_accuracy: 0.5833\n",
      "Epoch 127/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0292 - accuracy: 0.5238 - val_loss: 1.0002 - val_accuracy: 0.5833\n",
      "Epoch 128/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0389 - accuracy: 0.5218 - val_loss: 1.0001 - val_accuracy: 0.6012\n",
      "Epoch 129/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0430 - accuracy: 0.5456 - val_loss: 1.0074 - val_accuracy: 0.6071\n",
      "Epoch 130/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0040 - accuracy: 0.5536 - val_loss: 1.0103 - val_accuracy: 0.5952\n",
      "Epoch 131/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9879 - accuracy: 0.5635 - val_loss: 1.0351 - val_accuracy: 0.5536\n",
      "Epoch 132/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9743 - accuracy: 0.5972 - val_loss: 1.0177 - val_accuracy: 0.5774\n",
      "Epoch 133/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0041 - accuracy: 0.5278 - val_loss: 1.0180 - val_accuracy: 0.5893\n",
      "Epoch 134/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0114 - accuracy: 0.5298 - val_loss: 1.0311 - val_accuracy: 0.5357\n",
      "Epoch 135/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0109 - accuracy: 0.5099 - val_loss: 1.0128 - val_accuracy: 0.5833\n",
      "Epoch 136/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9783 - accuracy: 0.5813 - val_loss: 1.0029 - val_accuracy: 0.5714\n",
      "Epoch 137/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9945 - accuracy: 0.5337 - val_loss: 1.0009 - val_accuracy: 0.5893\n",
      "Epoch 138/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0402 - accuracy: 0.5258 - val_loss: 1.0030 - val_accuracy: 0.5893\n",
      "Epoch 139/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0134 - accuracy: 0.5615 - val_loss: 1.0193 - val_accuracy: 0.5774\n",
      "Epoch 140/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0150 - accuracy: 0.5456 - val_loss: 1.0159 - val_accuracy: 0.5714\n",
      "Epoch 141/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0005 - accuracy: 0.5536 - val_loss: 1.0130 - val_accuracy: 0.5536\n",
      "Epoch 142/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9657 - accuracy: 0.5813 - val_loss: 1.0197 - val_accuracy: 0.5714\n",
      "Epoch 143/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9895 - accuracy: 0.5595 - val_loss: 1.0108 - val_accuracy: 0.5774\n",
      "Epoch 144/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0182 - accuracy: 0.5337 - val_loss: 1.0132 - val_accuracy: 0.5714\n",
      "Epoch 145/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9844 - accuracy: 0.5595 - val_loss: 1.0287 - val_accuracy: 0.5298\n",
      "Epoch 146/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9626 - accuracy: 0.5575 - val_loss: 1.0374 - val_accuracy: 0.5179\n",
      "Epoch 147/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9827 - accuracy: 0.5337 - val_loss: 1.0357 - val_accuracy: 0.5060\n",
      "Epoch 148/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9234 - accuracy: 0.6071 - val_loss: 1.0158 - val_accuracy: 0.5595\n",
      "Epoch 149/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0048 - accuracy: 0.5456 - val_loss: 1.0069 - val_accuracy: 0.5655\n",
      "Epoch 150/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9729 - accuracy: 0.5556 - val_loss: 1.0351 - val_accuracy: 0.4940\n",
      "Epoch 151/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9813 - accuracy: 0.5317 - val_loss: 1.0050 - val_accuracy: 0.5655\n",
      "Epoch 152/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9846 - accuracy: 0.5595 - val_loss: 1.0031 - val_accuracy: 0.5714\n",
      "Epoch 153/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9900 - accuracy: 0.5377 - val_loss: 0.9982 - val_accuracy: 0.5833\n",
      "Epoch 154/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9414 - accuracy: 0.5873 - val_loss: 1.0196 - val_accuracy: 0.5238\n",
      "Epoch 155/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9429 - accuracy: 0.5833 - val_loss: 1.0154 - val_accuracy: 0.5298\n",
      "Epoch 156/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9669 - accuracy: 0.5437 - val_loss: 1.0051 - val_accuracy: 0.5595\n",
      "Epoch 157/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9542 - accuracy: 0.5754 - val_loss: 0.9967 - val_accuracy: 0.5655\n",
      "Epoch 158/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9679 - accuracy: 0.5417 - val_loss: 1.0074 - val_accuracy: 0.5595\n",
      "Epoch 159/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9709 - accuracy: 0.5635 - val_loss: 1.0143 - val_accuracy: 0.5417\n",
      "Epoch 160/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9487 - accuracy: 0.5595 - val_loss: 1.0060 - val_accuracy: 0.5417\n",
      "Epoch 161/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9638 - accuracy: 0.5694 - val_loss: 0.9808 - val_accuracy: 0.5833\n",
      "Epoch 162/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9578 - accuracy: 0.5734 - val_loss: 0.9855 - val_accuracy: 0.5833\n",
      "Epoch 163/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9431 - accuracy: 0.5794 - val_loss: 1.0045 - val_accuracy: 0.5774\n",
      "Epoch 164/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9537 - accuracy: 0.5595 - val_loss: 0.9928 - val_accuracy: 0.5774\n",
      "Epoch 165/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9464 - accuracy: 0.5754 - val_loss: 0.9840 - val_accuracy: 0.5714\n",
      "Epoch 166/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9684 - accuracy: 0.5516 - val_loss: 0.9944 - val_accuracy: 0.5714\n",
      "Epoch 167/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9298 - accuracy: 0.5794 - val_loss: 0.9909 - val_accuracy: 0.5476\n",
      "Epoch 168/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9386 - accuracy: 0.5813 - val_loss: 0.9712 - val_accuracy: 0.5774\n",
      "Epoch 169/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9598 - accuracy: 0.5694 - val_loss: 0.9644 - val_accuracy: 0.5833\n",
      "Epoch 170/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9465 - accuracy: 0.5833 - val_loss: 0.9675 - val_accuracy: 0.5774\n",
      "Epoch 171/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9608 - accuracy: 0.5556 - val_loss: 0.9969 - val_accuracy: 0.5357\n",
      "Epoch 172/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9262 - accuracy: 0.5972 - val_loss: 0.9945 - val_accuracy: 0.5417\n",
      "Epoch 173/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9171 - accuracy: 0.5893 - val_loss: 0.9961 - val_accuracy: 0.5417\n",
      "Epoch 174/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9225 - accuracy: 0.5992 - val_loss: 0.9815 - val_accuracy: 0.5833\n",
      "Epoch 175/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9308 - accuracy: 0.5536 - val_loss: 0.9887 - val_accuracy: 0.5714\n",
      "Epoch 176/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9531 - accuracy: 0.5476 - val_loss: 0.9944 - val_accuracy: 0.5357\n",
      "Epoch 177/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9222 - accuracy: 0.5893 - val_loss: 0.9732 - val_accuracy: 0.5893\n",
      "Epoch 178/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9365 - accuracy: 0.5794 - val_loss: 0.9888 - val_accuracy: 0.5476\n",
      "Epoch 179/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9232 - accuracy: 0.5952 - val_loss: 0.9766 - val_accuracy: 0.5714\n",
      "Epoch 180/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9214 - accuracy: 0.5952 - val_loss: 0.9652 - val_accuracy: 0.5833\n",
      "Epoch 181/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9250 - accuracy: 0.6012 - val_loss: 0.9581 - val_accuracy: 0.6012\n",
      "Epoch 182/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9317 - accuracy: 0.5992 - val_loss: 0.9479 - val_accuracy: 0.6012\n",
      "Epoch 183/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9377 - accuracy: 0.5774 - val_loss: 0.9584 - val_accuracy: 0.5893\n",
      "Epoch 184/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9135 - accuracy: 0.6131 - val_loss: 0.9773 - val_accuracy: 0.5655\n",
      "Epoch 185/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9222 - accuracy: 0.5794 - val_loss: 0.9717 - val_accuracy: 0.5655\n",
      "Epoch 186/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9357 - accuracy: 0.5417 - val_loss: 0.9639 - val_accuracy: 0.5952\n",
      "Epoch 187/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9225 - accuracy: 0.5754 - val_loss: 0.9961 - val_accuracy: 0.4940\n",
      "Epoch 188/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9063 - accuracy: 0.5933 - val_loss: 0.9685 - val_accuracy: 0.5833\n",
      "Epoch 189/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9082 - accuracy: 0.5992 - val_loss: 0.9688 - val_accuracy: 0.5774\n",
      "Epoch 190/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9244 - accuracy: 0.5992 - val_loss: 0.9680 - val_accuracy: 0.5655\n",
      "Epoch 191/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8813 - accuracy: 0.6012 - val_loss: 0.9442 - val_accuracy: 0.6131\n",
      "Epoch 192/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9073 - accuracy: 0.5853 - val_loss: 0.9545 - val_accuracy: 0.5893\n",
      "Epoch 193/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9137 - accuracy: 0.6032 - val_loss: 0.9702 - val_accuracy: 0.5833\n",
      "Epoch 194/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8785 - accuracy: 0.6369 - val_loss: 0.9476 - val_accuracy: 0.6012\n",
      "Epoch 195/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8735 - accuracy: 0.6210 - val_loss: 0.9530 - val_accuracy: 0.5893\n",
      "Epoch 196/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.8861 - accuracy: 0.6111 - val_loss: 0.9480 - val_accuracy: 0.5952\n",
      "Epoch 197/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8732 - accuracy: 0.6190 - val_loss: 0.9475 - val_accuracy: 0.5952\n",
      "Epoch 198/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9270 - accuracy: 0.5774 - val_loss: 0.9498 - val_accuracy: 0.5952\n",
      "Epoch 199/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8990 - accuracy: 0.6012 - val_loss: 0.9524 - val_accuracy: 0.5893\n",
      "Epoch 200/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8770 - accuracy: 0.6488 - val_loss: 0.9326 - val_accuracy: 0.5952\n",
      "Epoch 201/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8821 - accuracy: 0.5992 - val_loss: 0.9380 - val_accuracy: 0.5833\n",
      "Epoch 202/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8703 - accuracy: 0.6349 - val_loss: 0.9276 - val_accuracy: 0.6071\n",
      "Epoch 203/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9099 - accuracy: 0.6151 - val_loss: 0.9436 - val_accuracy: 0.6071\n",
      "Epoch 204/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9000 - accuracy: 0.5972 - val_loss: 0.9476 - val_accuracy: 0.6012\n",
      "Epoch 205/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8884 - accuracy: 0.6210 - val_loss: 0.9447 - val_accuracy: 0.5774\n",
      "Epoch 206/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9080 - accuracy: 0.6032 - val_loss: 0.9459 - val_accuracy: 0.5714\n",
      "Epoch 207/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8860 - accuracy: 0.6250 - val_loss: 0.9298 - val_accuracy: 0.6071\n",
      "Epoch 208/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8767 - accuracy: 0.6111 - val_loss: 0.9457 - val_accuracy: 0.5833\n",
      "Epoch 209/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8671 - accuracy: 0.6230 - val_loss: 0.9459 - val_accuracy: 0.5774\n",
      "Epoch 210/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8614 - accuracy: 0.6111 - val_loss: 0.9270 - val_accuracy: 0.6369\n",
      "Epoch 211/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.8674 - accuracy: 0.6389 - val_loss: 0.9367 - val_accuracy: 0.6071\n",
      "Epoch 212/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8996 - accuracy: 0.5972 - val_loss: 0.9297 - val_accuracy: 0.6190\n",
      "Epoch 213/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8902 - accuracy: 0.6131 - val_loss: 0.9278 - val_accuracy: 0.6190\n",
      "Epoch 214/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8773 - accuracy: 0.6111 - val_loss: 0.9440 - val_accuracy: 0.5952\n",
      "Epoch 215/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8816 - accuracy: 0.6131 - val_loss: 0.9250 - val_accuracy: 0.6250\n",
      "Epoch 216/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8991 - accuracy: 0.5972 - val_loss: 0.9552 - val_accuracy: 0.5476\n",
      "Epoch 217/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.8695 - accuracy: 0.6329 - val_loss: 0.9243 - val_accuracy: 0.6012\n",
      "Epoch 218/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8841 - accuracy: 0.6270 - val_loss: 0.9264 - val_accuracy: 0.6190\n",
      "Epoch 219/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8673 - accuracy: 0.6111 - val_loss: 0.9388 - val_accuracy: 0.6190\n",
      "Epoch 220/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8644 - accuracy: 0.6290 - val_loss: 0.9373 - val_accuracy: 0.6131\n",
      "Epoch 221/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8723 - accuracy: 0.6290 - val_loss: 0.9312 - val_accuracy: 0.6012\n",
      "Epoch 222/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8601 - accuracy: 0.6131 - val_loss: 0.9316 - val_accuracy: 0.6071\n",
      "Epoch 223/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8750 - accuracy: 0.6091 - val_loss: 0.9242 - val_accuracy: 0.6012\n",
      "Epoch 224/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8792 - accuracy: 0.6071 - val_loss: 0.9212 - val_accuracy: 0.6310\n",
      "Epoch 225/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8609 - accuracy: 0.6349 - val_loss: 0.9283 - val_accuracy: 0.6012\n",
      "Epoch 226/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8529 - accuracy: 0.6369 - val_loss: 0.9114 - val_accuracy: 0.6429\n",
      "Epoch 227/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8455 - accuracy: 0.6349 - val_loss: 0.9208 - val_accuracy: 0.6012\n",
      "Epoch 228/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8606 - accuracy: 0.6131 - val_loss: 0.9347 - val_accuracy: 0.5893\n",
      "Epoch 229/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8574 - accuracy: 0.5992 - val_loss: 0.9284 - val_accuracy: 0.6131\n",
      "Epoch 230/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8473 - accuracy: 0.6349 - val_loss: 0.9176 - val_accuracy: 0.6071\n",
      "Epoch 231/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8694 - accuracy: 0.6210 - val_loss: 0.9118 - val_accuracy: 0.6429\n",
      "Epoch 232/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8691 - accuracy: 0.6468 - val_loss: 0.9075 - val_accuracy: 0.6429\n",
      "Epoch 233/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8837 - accuracy: 0.6171 - val_loss: 0.9190 - val_accuracy: 0.6190\n",
      "Epoch 234/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8469 - accuracy: 0.6151 - val_loss: 0.9097 - val_accuracy: 0.6310\n",
      "Epoch 235/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8606 - accuracy: 0.6250 - val_loss: 0.9015 - val_accuracy: 0.6548\n",
      "Epoch 236/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8510 - accuracy: 0.6369 - val_loss: 0.9098 - val_accuracy: 0.6012\n",
      "Epoch 237/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8770 - accuracy: 0.6131 - val_loss: 0.9208 - val_accuracy: 0.6012\n",
      "Epoch 238/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8369 - accuracy: 0.6508 - val_loss: 0.9234 - val_accuracy: 0.6131\n",
      "Epoch 239/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8529 - accuracy: 0.6091 - val_loss: 0.9168 - val_accuracy: 0.5952\n",
      "Epoch 240/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8413 - accuracy: 0.6488 - val_loss: 0.9466 - val_accuracy: 0.5833\n",
      "Epoch 241/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8330 - accuracy: 0.6528 - val_loss: 0.9044 - val_accuracy: 0.6190\n",
      "Epoch 242/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8758 - accuracy: 0.6111 - val_loss: 0.9134 - val_accuracy: 0.5893\n",
      "Epoch 243/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8573 - accuracy: 0.6230 - val_loss: 0.9204 - val_accuracy: 0.6071\n",
      "Epoch 244/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8651 - accuracy: 0.6091 - val_loss: 0.9131 - val_accuracy: 0.6190\n",
      "Epoch 245/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8359 - accuracy: 0.6270 - val_loss: 0.9245 - val_accuracy: 0.5952\n",
      "Epoch 246/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8333 - accuracy: 0.6250 - val_loss: 0.8996 - val_accuracy: 0.6488\n",
      "Epoch 247/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8349 - accuracy: 0.6409 - val_loss: 0.9180 - val_accuracy: 0.6131\n",
      "Epoch 248/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8515 - accuracy: 0.6389 - val_loss: 0.9059 - val_accuracy: 0.6190\n",
      "Epoch 249/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8662 - accuracy: 0.6429 - val_loss: 0.9205 - val_accuracy: 0.6190\n",
      "Epoch 250/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8332 - accuracy: 0.6607 - val_loss: 0.9070 - val_accuracy: 0.6310\n",
      "Epoch 251/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8374 - accuracy: 0.6488 - val_loss: 0.9173 - val_accuracy: 0.6250\n",
      "Epoch 252/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8265 - accuracy: 0.6528 - val_loss: 0.9076 - val_accuracy: 0.6071\n",
      "Epoch 253/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8312 - accuracy: 0.6488 - val_loss: 0.8981 - val_accuracy: 0.6190\n",
      "Epoch 254/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8375 - accuracy: 0.6488 - val_loss: 0.9105 - val_accuracy: 0.6071\n",
      "Epoch 255/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8396 - accuracy: 0.6429 - val_loss: 0.9066 - val_accuracy: 0.6250\n",
      "Epoch 256/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8252 - accuracy: 0.6310 - val_loss: 0.9224 - val_accuracy: 0.6131\n",
      "Epoch 257/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8232 - accuracy: 0.6389 - val_loss: 0.8913 - val_accuracy: 0.6488\n",
      "Epoch 258/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8206 - accuracy: 0.6369 - val_loss: 0.9325 - val_accuracy: 0.5833\n",
      "Epoch 259/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8297 - accuracy: 0.6468 - val_loss: 0.9183 - val_accuracy: 0.6012\n",
      "Epoch 260/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8392 - accuracy: 0.6111 - val_loss: 0.9033 - val_accuracy: 0.6071\n",
      "Epoch 261/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8297 - accuracy: 0.6349 - val_loss: 0.9097 - val_accuracy: 0.6190\n",
      "Epoch 262/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8432 - accuracy: 0.6230 - val_loss: 0.9025 - val_accuracy: 0.6071\n",
      "Epoch 263/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8425 - accuracy: 0.6349 - val_loss: 0.9078 - val_accuracy: 0.6190\n",
      "Epoch 264/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8214 - accuracy: 0.6349 - val_loss: 0.8915 - val_accuracy: 0.6369\n",
      "Epoch 265/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8410 - accuracy: 0.6329 - val_loss: 0.9055 - val_accuracy: 0.6131\n",
      "Epoch 266/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8054 - accuracy: 0.6548 - val_loss: 0.8926 - val_accuracy: 0.6190\n",
      "Epoch 267/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8143 - accuracy: 0.6627 - val_loss: 0.9071 - val_accuracy: 0.5952\n",
      "Epoch 268/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.7999 - accuracy: 0.6667 - val_loss: 0.8917 - val_accuracy: 0.6429\n",
      "Epoch 269/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8211 - accuracy: 0.6528 - val_loss: 0.8933 - val_accuracy: 0.6190\n",
      "Epoch 270/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8121 - accuracy: 0.6567 - val_loss: 0.9001 - val_accuracy: 0.6131\n",
      "Epoch 271/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8185 - accuracy: 0.6448 - val_loss: 0.8991 - val_accuracy: 0.6131\n",
      "Epoch 272/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8224 - accuracy: 0.6488 - val_loss: 0.8921 - val_accuracy: 0.6190\n",
      "Epoch 273/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8133 - accuracy: 0.6329 - val_loss: 0.9141 - val_accuracy: 0.6131\n",
      "Epoch 274/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8051 - accuracy: 0.6806 - val_loss: 0.9240 - val_accuracy: 0.6250\n",
      "Epoch 275/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7822 - accuracy: 0.6746 - val_loss: 0.8839 - val_accuracy: 0.6488\n",
      "Epoch 276/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8163 - accuracy: 0.6349 - val_loss: 0.8983 - val_accuracy: 0.6071\n",
      "Epoch 277/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7971 - accuracy: 0.6825 - val_loss: 0.8994 - val_accuracy: 0.6071\n",
      "Epoch 278/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8025 - accuracy: 0.6567 - val_loss: 0.9201 - val_accuracy: 0.5774\n",
      "Epoch 279/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8271 - accuracy: 0.6488 - val_loss: 0.9011 - val_accuracy: 0.6071\n",
      "Epoch 280/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8071 - accuracy: 0.6488 - val_loss: 0.9170 - val_accuracy: 0.6012\n",
      "Epoch 281/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7989 - accuracy: 0.6607 - val_loss: 0.8796 - val_accuracy: 0.6488\n",
      "Epoch 282/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.8234 - accuracy: 0.6409 - val_loss: 0.8901 - val_accuracy: 0.6190\n",
      "Epoch 283/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8125 - accuracy: 0.6508 - val_loss: 0.8939 - val_accuracy: 0.6131\n",
      "Epoch 284/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8197 - accuracy: 0.6687 - val_loss: 0.9086 - val_accuracy: 0.6071\n",
      "Epoch 285/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7812 - accuracy: 0.6567 - val_loss: 0.9006 - val_accuracy: 0.6012\n",
      "Epoch 286/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8198 - accuracy: 0.6389 - val_loss: 0.8860 - val_accuracy: 0.6310\n",
      "Epoch 287/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8088 - accuracy: 0.6567 - val_loss: 0.8908 - val_accuracy: 0.6131\n",
      "Epoch 288/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7897 - accuracy: 0.6687 - val_loss: 0.9012 - val_accuracy: 0.6071\n",
      "Epoch 289/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7955 - accuracy: 0.6706 - val_loss: 0.8735 - val_accuracy: 0.6488\n",
      "Epoch 290/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7950 - accuracy: 0.6508 - val_loss: 0.8828 - val_accuracy: 0.6250\n",
      "Epoch 291/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7989 - accuracy: 0.6369 - val_loss: 0.8855 - val_accuracy: 0.6310\n",
      "Epoch 292/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8027 - accuracy: 0.6687 - val_loss: 0.8893 - val_accuracy: 0.6131\n",
      "Epoch 293/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8047 - accuracy: 0.6548 - val_loss: 0.8882 - val_accuracy: 0.6131\n",
      "Epoch 294/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8219 - accuracy: 0.6627 - val_loss: 0.8891 - val_accuracy: 0.6071\n",
      "Epoch 295/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7905 - accuracy: 0.6706 - val_loss: 0.8789 - val_accuracy: 0.6310\n",
      "Epoch 296/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8003 - accuracy: 0.6567 - val_loss: 0.8706 - val_accuracy: 0.6369\n",
      "Epoch 297/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7956 - accuracy: 0.6488 - val_loss: 0.8829 - val_accuracy: 0.6190\n",
      "Epoch 298/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7884 - accuracy: 0.6825 - val_loss: 0.8842 - val_accuracy: 0.6369\n",
      "Epoch 299/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.7929 - accuracy: 0.6587 - val_loss: 0.8755 - val_accuracy: 0.6369\n",
      "Epoch 300/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7872 - accuracy: 0.6726 - val_loss: 0.8780 - val_accuracy: 0.6429\n",
      "Epoch 301/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7880 - accuracy: 0.6706 - val_loss: 0.8942 - val_accuracy: 0.6012\n",
      "Epoch 302/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8146 - accuracy: 0.6369 - val_loss: 0.8855 - val_accuracy: 0.6250\n",
      "Epoch 303/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7890 - accuracy: 0.6508 - val_loss: 0.8906 - val_accuracy: 0.6190\n",
      "Epoch 304/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7928 - accuracy: 0.6369 - val_loss: 0.8759 - val_accuracy: 0.6369\n",
      "Epoch 305/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.7946 - accuracy: 0.6508 - val_loss: 0.8772 - val_accuracy: 0.6488\n",
      "Epoch 306/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7761 - accuracy: 0.6726 - val_loss: 0.8888 - val_accuracy: 0.6131\n",
      "Epoch 307/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7931 - accuracy: 0.6746 - val_loss: 0.8804 - val_accuracy: 0.6190\n",
      "Epoch 308/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.7608 - accuracy: 0.6905 - val_loss: 0.8894 - val_accuracy: 0.5952\n",
      "Epoch 309/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8083 - accuracy: 0.6627 - val_loss: 0.8728 - val_accuracy: 0.6369\n",
      "Epoch 310/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7947 - accuracy: 0.66 - 0s 21ms/step - loss: 0.7947 - accuracy: 0.6627 - val_loss: 0.8947 - val_accuracy: 0.5952\n",
      "Epoch 311/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7898 - accuracy: 0.6508 - val_loss: 0.8860 - val_accuracy: 0.6131\n",
      "Epoch 312/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7774 - accuracy: 0.6726 - val_loss: 0.8882 - val_accuracy: 0.6012\n",
      "Epoch 313/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7905 - accuracy: 0.6567 - val_loss: 0.8799 - val_accuracy: 0.6369\n",
      "Epoch 314/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.7811 - accuracy: 0.6687 - val_loss: 0.8770 - val_accuracy: 0.6429\n",
      "Epoch 315/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7848 - accuracy: 0.6706 - val_loss: 0.8912 - val_accuracy: 0.6131\n",
      "Epoch 316/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.7701 - accuracy: 0.6786 - val_loss: 0.8782 - val_accuracy: 0.6250\n",
      "Epoch 317/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.7915 - accuracy: 0.6567 - val_loss: 0.8743 - val_accuracy: 0.6310\n",
      "Epoch 318/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7730 - accuracy: 0.6865 - val_loss: 0.8758 - val_accuracy: 0.6190\n",
      "Epoch 319/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7717 - accuracy: 0.6706 - val_loss: 0.9014 - val_accuracy: 0.6071\n",
      "Epoch 320/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7769 - accuracy: 0.6726 - val_loss: 0.8633 - val_accuracy: 0.6369\n",
      "Epoch 321/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7866 - accuracy: 0.6528 - val_loss: 0.8636 - val_accuracy: 0.6250\n",
      "Epoch 322/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7809 - accuracy: 0.6706 - val_loss: 0.8707 - val_accuracy: 0.6190\n",
      "Epoch 323/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7675 - accuracy: 0.6865 - val_loss: 0.8710 - val_accuracy: 0.6369\n",
      "Epoch 324/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7935 - accuracy: 0.6746 - val_loss: 0.8789 - val_accuracy: 0.6310\n",
      "Epoch 325/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.7749 - accuracy: 0.6825 - val_loss: 0.8726 - val_accuracy: 0.6190\n",
      "Epoch 326/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7619 - accuracy: 0.6766 - val_loss: 0.8651 - val_accuracy: 0.6429\n",
      "Epoch 327/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.7628 - accuracy: 0.6786 - val_loss: 0.8690 - val_accuracy: 0.6250\n",
      "Epoch 328/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7480 - accuracy: 0.6786 - val_loss: 0.8689 - val_accuracy: 0.6190\n",
      "Epoch 329/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.7663 - accuracy: 0.6806 - val_loss: 0.8877 - val_accuracy: 0.6131\n",
      "Epoch 330/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.7753 - accuracy: 0.6627 - val_loss: 0.8731 - val_accuracy: 0.6071\n",
      "Epoch 331/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.7650 - accuracy: 0.7024 - val_loss: 0.8682 - val_accuracy: 0.6310\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 0.7836 - accuracy: 0.6667 - val_loss: 0.8554 - val_accuracy: 0.6429\n",
      "Epoch 333/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7457 - accuracy: 0.6964 - val_loss: 0.8657 - val_accuracy: 0.6310\n",
      "Epoch 334/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.7706 - accuracy: 0.6806 - val_loss: 0.8724 - val_accuracy: 0.6190\n",
      "Epoch 335/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.7809 - accuracy: 0.6687 - val_loss: 0.8660 - val_accuracy: 0.6190\n",
      "Epoch 336/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.7530 - accuracy: 0.6825 - val_loss: 0.8695 - val_accuracy: 0.6250\n",
      "Epoch 337/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7373 - accuracy: 0.6925 - val_loss: 0.8634 - val_accuracy: 0.6310\n",
      "Epoch 338/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7473 - accuracy: 0.6885 - val_loss: 0.8551 - val_accuracy: 0.6310\n",
      "Epoch 339/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7602 - accuracy: 0.6647 - val_loss: 0.8873 - val_accuracy: 0.6131\n",
      "Epoch 340/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7684 - accuracy: 0.6845 - val_loss: 0.8544 - val_accuracy: 0.6369\n",
      "Epoch 341/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7709 - accuracy: 0.6865 - val_loss: 0.8672 - val_accuracy: 0.6131\n",
      "Epoch 342/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7660 - accuracy: 0.6548 - val_loss: 0.8648 - val_accuracy: 0.6250\n",
      "Epoch 343/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7569 - accuracy: 0.6984 - val_loss: 0.8501 - val_accuracy: 0.6548\n",
      "Epoch 344/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.7543 - accuracy: 0.6825 - val_loss: 0.8536 - val_accuracy: 0.6250\n",
      "Epoch 345/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7382 - accuracy: 0.7063 - val_loss: 0.8659 - val_accuracy: 0.6071\n",
      "Epoch 346/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.7484 - accuracy: 0.6865 - val_loss: 0.8648 - val_accuracy: 0.6429\n",
      "Epoch 347/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7406 - accuracy: 0.6964 - val_loss: 0.8541 - val_accuracy: 0.6607\n",
      "Epoch 348/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7471 - accuracy: 0.6964 - val_loss: 0.8614 - val_accuracy: 0.6250\n",
      "Epoch 349/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7280 - accuracy: 0.6746 - val_loss: 0.8536 - val_accuracy: 0.6429\n",
      "Epoch 350/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7466 - accuracy: 0.6746 - val_loss: 0.8546 - val_accuracy: 0.6310\n",
      "Epoch 351/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.7456 - accuracy: 0.6825 - val_loss: 0.8512 - val_accuracy: 0.6429\n",
      "Epoch 352/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7527 - accuracy: 0.6885 - val_loss: 0.8559 - val_accuracy: 0.6429\n",
      "Epoch 353/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.7463 - accuracy: 0.6766 - val_loss: 0.8522 - val_accuracy: 0.6429\n",
      "Epoch 354/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7615 - accuracy: 0.6786 - val_loss: 0.8834 - val_accuracy: 0.6131\n",
      "Epoch 355/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7606 - accuracy: 0.6687 - val_loss: 0.8892 - val_accuracy: 0.6131\n",
      "Epoch 356/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7363 - accuracy: 0.6587 - val_loss: 0.8572 - val_accuracy: 0.6250\n",
      "Epoch 357/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7524 - accuracy: 0.6706 - val_loss: 0.8610 - val_accuracy: 0.6250\n",
      "Epoch 358/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7629 - accuracy: 0.6865 - val_loss: 0.8505 - val_accuracy: 0.6369\n",
      "Epoch 359/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7673 - accuracy: 0.6806 - val_loss: 0.8653 - val_accuracy: 0.6131\n",
      "Epoch 360/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7642 - accuracy: 0.6905 - val_loss: 0.8647 - val_accuracy: 0.6131\n",
      "Epoch 361/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7637 - accuracy: 0.6885 - val_loss: 0.8509 - val_accuracy: 0.6131\n",
      "Epoch 362/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7461 - accuracy: 0.6845 - val_loss: 0.8578 - val_accuracy: 0.6429\n",
      "Epoch 363/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7484 - accuracy: 0.6865 - val_loss: 0.8687 - val_accuracy: 0.6190\n",
      "Epoch 364/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7353 - accuracy: 0.6964 - val_loss: 0.8623 - val_accuracy: 0.6131\n",
      "Epoch 365/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7545 - accuracy: 0.6865 - val_loss: 0.8467 - val_accuracy: 0.6310\n",
      "Epoch 366/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7415 - accuracy: 0.6766 - val_loss: 0.8573 - val_accuracy: 0.6190\n",
      "Epoch 367/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7271 - accuracy: 0.7103 - val_loss: 0.8507 - val_accuracy: 0.6071\n",
      "Epoch 368/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7362 - accuracy: 0.7103 - val_loss: 0.8765 - val_accuracy: 0.6190\n",
      "Epoch 369/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7526 - accuracy: 0.6825 - val_loss: 0.8436 - val_accuracy: 0.6369\n",
      "Epoch 370/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7432 - accuracy: 0.6885 - val_loss: 0.8816 - val_accuracy: 0.6310\n",
      "Epoch 371/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7461 - accuracy: 0.6964 - val_loss: 0.8841 - val_accuracy: 0.6131\n",
      "Epoch 372/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7434 - accuracy: 0.6984 - val_loss: 0.8460 - val_accuracy: 0.6369\n",
      "Epoch 373/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7567 - accuracy: 0.7044 - val_loss: 0.8804 - val_accuracy: 0.6310\n",
      "Epoch 374/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7188 - accuracy: 0.6825 - val_loss: 0.8536 - val_accuracy: 0.6310\n",
      "Epoch 375/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7474 - accuracy: 0.6885 - val_loss: 0.8726 - val_accuracy: 0.6131\n",
      "Epoch 376/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7318 - accuracy: 0.6925 - val_loss: 0.8606 - val_accuracy: 0.6190\n",
      "Epoch 377/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7493 - accuracy: 0.6766 - val_loss: 0.8558 - val_accuracy: 0.6310\n",
      "Epoch 378/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7386 - accuracy: 0.6984 - val_loss: 0.8494 - val_accuracy: 0.6369\n",
      "Epoch 379/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7334 - accuracy: 0.6845 - val_loss: 0.8598 - val_accuracy: 0.6310\n",
      "Epoch 380/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7300 - accuracy: 0.7183 - val_loss: 0.8729 - val_accuracy: 0.6250\n",
      "Epoch 381/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7309 - accuracy: 0.7004 - val_loss: 0.8680 - val_accuracy: 0.6071\n",
      "Epoch 382/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7198 - accuracy: 0.6984 - val_loss: 0.8543 - val_accuracy: 0.6310\n",
      "Epoch 383/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7438 - accuracy: 0.6984 - val_loss: 0.8514 - val_accuracy: 0.6190\n",
      "Epoch 384/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7228 - accuracy: 0.6964 - val_loss: 0.8463 - val_accuracy: 0.6369\n",
      "Epoch 385/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7199 - accuracy: 0.6964 - val_loss: 0.8460 - val_accuracy: 0.6429\n",
      "Epoch 386/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7056 - accuracy: 0.7063 - val_loss: 0.8555 - val_accuracy: 0.6190\n",
      "Epoch 387/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7057 - accuracy: 0.7163 - val_loss: 0.8545 - val_accuracy: 0.6250\n",
      "Epoch 388/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7410 - accuracy: 0.6865 - val_loss: 0.8457 - val_accuracy: 0.6369\n",
      "Epoch 389/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7321 - accuracy: 0.7024 - val_loss: 0.8506 - val_accuracy: 0.6429\n",
      "Epoch 390/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7163 - accuracy: 0.7103 - val_loss: 0.8443 - val_accuracy: 0.6429\n",
      "Epoch 391/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7222 - accuracy: 0.6806 - val_loss: 0.8681 - val_accuracy: 0.6190\n",
      "Epoch 392/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7317 - accuracy: 0.6925 - val_loss: 0.8456 - val_accuracy: 0.6310\n",
      "Epoch 393/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7345 - accuracy: 0.6885 - val_loss: 0.8458 - val_accuracy: 0.6369\n",
      "Epoch 394/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7273 - accuracy: 0.7063 - val_loss: 0.8480 - val_accuracy: 0.6071\n",
      "Epoch 395/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7067 - accuracy: 0.7222 - val_loss: 0.8686 - val_accuracy: 0.6131\n",
      "Epoch 396/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7249 - accuracy: 0.6825 - val_loss: 0.8399 - val_accuracy: 0.6310\n",
      "Epoch 397/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7028 - accuracy: 0.7123 - val_loss: 0.8802 - val_accuracy: 0.6071\n",
      "Epoch 398/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7204 - accuracy: 0.7083 - val_loss: 0.8476 - val_accuracy: 0.6429\n",
      "Epoch 399/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7198 - accuracy: 0.6925 - val_loss: 0.8538 - val_accuracy: 0.6131\n",
      "Epoch 400/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7157 - accuracy: 0.6925 - val_loss: 0.8791 - val_accuracy: 0.6071\n",
      "Epoch 401/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7223 - accuracy: 0.6885 - val_loss: 0.8523 - val_accuracy: 0.6131\n",
      "Epoch 402/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7110 - accuracy: 0.7361 - val_loss: 0.8548 - val_accuracy: 0.6190\n",
      "Epoch 403/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7217 - accuracy: 0.7222 - val_loss: 0.8486 - val_accuracy: 0.6190\n",
      "Epoch 404/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7126 - accuracy: 0.7202 - val_loss: 0.8534 - val_accuracy: 0.6190\n",
      "Epoch 405/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6929 - accuracy: 0.7361 - val_loss: 0.8511 - val_accuracy: 0.6250\n",
      "Epoch 406/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7209 - accuracy: 0.6905 - val_loss: 0.8352 - val_accuracy: 0.6429\n",
      "Epoch 407/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7186 - accuracy: 0.6984 - val_loss: 0.8413 - val_accuracy: 0.6310\n",
      "Epoch 408/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7041 - accuracy: 0.7302 - val_loss: 0.8334 - val_accuracy: 0.6429\n",
      "Epoch 409/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7304 - accuracy: 0.7024 - val_loss: 0.8788 - val_accuracy: 0.6131\n",
      "Epoch 410/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7279 - accuracy: 0.7004 - val_loss: 0.8672 - val_accuracy: 0.6250\n",
      "Epoch 411/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7315 - accuracy: 0.7004 - val_loss: 0.8444 - val_accuracy: 0.6310\n",
      "Epoch 412/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7162 - accuracy: 0.7044 - val_loss: 0.8443 - val_accuracy: 0.6250\n",
      "Epoch 413/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7129 - accuracy: 0.7083 - val_loss: 0.8712 - val_accuracy: 0.6310\n",
      "Epoch 414/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6995 - accuracy: 0.7083 - val_loss: 0.8546 - val_accuracy: 0.6131\n",
      "Epoch 415/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7122 - accuracy: 0.7103 - val_loss: 0.8333 - val_accuracy: 0.6369\n",
      "Epoch 416/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7089 - accuracy: 0.7063 - val_loss: 0.8286 - val_accuracy: 0.6310\n",
      "Epoch 417/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7079 - accuracy: 0.7103 - val_loss: 0.8368 - val_accuracy: 0.6369\n",
      "Epoch 418/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7119 - accuracy: 0.7123 - val_loss: 0.8322 - val_accuracy: 0.6310\n",
      "Epoch 419/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7238 - accuracy: 0.6984 - val_loss: 0.8348 - val_accuracy: 0.6429\n",
      "Epoch 420/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6842 - accuracy: 0.7341 - val_loss: 0.8371 - val_accuracy: 0.6250\n",
      "Epoch 421/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7157 - accuracy: 0.7222 - val_loss: 0.8383 - val_accuracy: 0.6250\n",
      "Epoch 422/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7126 - accuracy: 0.7103 - val_loss: 0.8371 - val_accuracy: 0.6369\n",
      "Epoch 423/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7010 - accuracy: 0.7123 - val_loss: 0.8280 - val_accuracy: 0.6369\n",
      "Epoch 424/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7078 - accuracy: 0.6885 - val_loss: 0.8558 - val_accuracy: 0.6131\n",
      "Epoch 425/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6761 - accuracy: 0.7183 - val_loss: 0.8677 - val_accuracy: 0.6250\n",
      "Epoch 426/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6854 - accuracy: 0.7222 - val_loss: 0.8355 - val_accuracy: 0.6310\n",
      "Epoch 427/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7007 - accuracy: 0.7123 - val_loss: 0.8644 - val_accuracy: 0.6310\n",
      "Epoch 428/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6940 - accuracy: 0.7262 - val_loss: 0.8399 - val_accuracy: 0.6250\n",
      "Epoch 429/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7001 - accuracy: 0.7123 - val_loss: 0.8448 - val_accuracy: 0.6250\n",
      "Epoch 430/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6957 - accuracy: 0.7143 - val_loss: 0.8573 - val_accuracy: 0.6131\n",
      "Epoch 431/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6954 - accuracy: 0.7143 - val_loss: 0.8338 - val_accuracy: 0.6369\n",
      "Epoch 432/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6828 - accuracy: 0.7262 - val_loss: 0.8437 - val_accuracy: 0.6250\n",
      "Epoch 433/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6861 - accuracy: 0.7163 - val_loss: 0.8442 - val_accuracy: 0.6250\n",
      "Epoch 434/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6905 - accuracy: 0.7044 - val_loss: 0.8468 - val_accuracy: 0.6131\n",
      "Epoch 435/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6998 - accuracy: 0.7143 - val_loss: 0.8332 - val_accuracy: 0.6488\n",
      "Epoch 436/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6900 - accuracy: 0.7123 - val_loss: 0.8217 - val_accuracy: 0.6369\n",
      "Epoch 437/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6764 - accuracy: 0.7222 - val_loss: 0.8256 - val_accuracy: 0.6369\n",
      "Epoch 438/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7061 - accuracy: 0.7083 - val_loss: 0.8368 - val_accuracy: 0.6310\n",
      "Epoch 439/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6905 - accuracy: 0.7163 - val_loss: 0.8553 - val_accuracy: 0.6250\n",
      "Epoch 440/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6698 - accuracy: 0.7103 - val_loss: 0.8281 - val_accuracy: 0.6429\n",
      "Epoch 441/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6673 - accuracy: 0.7421 - val_loss: 0.8244 - val_accuracy: 0.6310\n",
      "Epoch 442/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7053 - accuracy: 0.7024 - val_loss: 0.8614 - val_accuracy: 0.5952\n",
      "Epoch 443/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6949 - accuracy: 0.7222 - val_loss: 0.8256 - val_accuracy: 0.6250\n",
      "Epoch 444/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6955 - accuracy: 0.7143 - val_loss: 0.8397 - val_accuracy: 0.6310\n",
      "Epoch 445/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6790 - accuracy: 0.7361 - val_loss: 0.8499 - val_accuracy: 0.6250\n",
      "Epoch 446/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6786 - accuracy: 0.7321 - val_loss: 0.8423 - val_accuracy: 0.6250\n",
      "Epoch 447/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6924 - accuracy: 0.7262 - val_loss: 0.8620 - val_accuracy: 0.6071\n",
      "Epoch 448/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6831 - accuracy: 0.7361 - val_loss: 0.8359 - val_accuracy: 0.6012\n",
      "Epoch 449/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6878 - accuracy: 0.7321 - val_loss: 0.8551 - val_accuracy: 0.6012\n",
      "Epoch 450/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6989 - accuracy: 0.7123 - val_loss: 0.8254 - val_accuracy: 0.6369\n",
      "Epoch 451/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6670 - accuracy: 0.7341 - val_loss: 0.8121 - val_accuracy: 0.6429\n",
      "Epoch 452/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6787 - accuracy: 0.7163 - val_loss: 0.8255 - val_accuracy: 0.6369\n",
      "Epoch 453/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7012 - accuracy: 0.7024 - val_loss: 0.8489 - val_accuracy: 0.6310\n",
      "Epoch 454/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7122 - accuracy: 0.7024 - val_loss: 0.8501 - val_accuracy: 0.6190\n",
      "Epoch 455/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6910 - accuracy: 0.7044 - val_loss: 0.8423 - val_accuracy: 0.6190\n",
      "Epoch 456/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6693 - accuracy: 0.7242 - val_loss: 0.8292 - val_accuracy: 0.6190\n",
      "Epoch 457/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6773 - accuracy: 0.7202 - val_loss: 0.8355 - val_accuracy: 0.6250\n",
      "Epoch 458/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6668 - accuracy: 0.7341 - val_loss: 0.8316 - val_accuracy: 0.6012\n",
      "Epoch 459/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.6984 - val_loss: 0.8569 - val_accuracy: 0.6131\n",
      "Epoch 460/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6914 - accuracy: 0.7123 - val_loss: 0.8297 - val_accuracy: 0.6250\n",
      "Epoch 461/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6765 - accuracy: 0.7361 - val_loss: 0.8157 - val_accuracy: 0.6131\n",
      "Epoch 462/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6935 - accuracy: 0.7103 - val_loss: 0.8256 - val_accuracy: 0.6250\n",
      "Epoch 463/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6968 - accuracy: 0.6925 - val_loss: 0.8203 - val_accuracy: 0.6310\n",
      "Epoch 464/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6632 - accuracy: 0.7262 - val_loss: 0.8372 - val_accuracy: 0.6190\n",
      "Epoch 465/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6743 - accuracy: 0.7222 - val_loss: 0.8231 - val_accuracy: 0.6429\n",
      "Epoch 466/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6883 - accuracy: 0.7063 - val_loss: 0.8377 - val_accuracy: 0.6071\n",
      "Epoch 467/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6754 - accuracy: 0.7401 - val_loss: 0.8229 - val_accuracy: 0.6429\n",
      "Epoch 468/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6656 - accuracy: 0.7063 - val_loss: 0.8219 - val_accuracy: 0.6369\n",
      "Epoch 469/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6833 - accuracy: 0.7262 - val_loss: 0.8197 - val_accuracy: 0.6190\n",
      "Epoch 470/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6806 - accuracy: 0.7202 - val_loss: 0.8247 - val_accuracy: 0.6369\n",
      "Epoch 471/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6814 - accuracy: 0.7282 - val_loss: 0.8141 - val_accuracy: 0.6071\n",
      "Epoch 472/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6664 - accuracy: 0.7321 - val_loss: 0.8084 - val_accuracy: 0.6369\n",
      "Epoch 473/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6686 - accuracy: 0.7321 - val_loss: 0.8204 - val_accuracy: 0.6369\n",
      "Epoch 474/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6704 - accuracy: 0.7202 - val_loss: 0.8233 - val_accuracy: 0.6310\n",
      "Epoch 475/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6636 - accuracy: 0.7401 - val_loss: 0.8219 - val_accuracy: 0.6071\n",
      "Epoch 476/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6668 - accuracy: 0.7302 - val_loss: 0.8159 - val_accuracy: 0.6250\n",
      "Epoch 477/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6720 - accuracy: 0.7143 - val_loss: 0.8353 - val_accuracy: 0.6250\n",
      "Epoch 478/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6675 - accuracy: 0.7202 - val_loss: 0.8372 - val_accuracy: 0.6310\n",
      "Epoch 479/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6621 - accuracy: 0.7222 - val_loss: 0.8203 - val_accuracy: 0.6250\n",
      "Epoch 480/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6688 - accuracy: 0.7381 - val_loss: 0.8171 - val_accuracy: 0.6369\n",
      "Epoch 481/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6801 - accuracy: 0.7341 - val_loss: 0.8248 - val_accuracy: 0.6310\n",
      "Epoch 482/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6634 - accuracy: 0.7242 - val_loss: 0.8180 - val_accuracy: 0.6310\n",
      "Epoch 483/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6643 - accuracy: 0.7282 - val_loss: 0.8261 - val_accuracy: 0.6369\n",
      "Epoch 484/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6657 - accuracy: 0.7480 - val_loss: 0.8130 - val_accuracy: 0.6548\n",
      "Epoch 485/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6699 - accuracy: 0.7302 - val_loss: 0.8160 - val_accuracy: 0.6250\n",
      "Epoch 486/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6508 - accuracy: 0.7599 - val_loss: 0.8263 - val_accuracy: 0.6429\n",
      "Epoch 487/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6578 - accuracy: 0.7401 - val_loss: 0.8163 - val_accuracy: 0.6310\n",
      "Epoch 488/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6380 - accuracy: 0.7440 - val_loss: 0.8086 - val_accuracy: 0.6190\n",
      "Epoch 489/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.6626 - accuracy: 0.7460 - val_loss: 0.8117 - val_accuracy: 0.6250\n",
      "Epoch 490/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6737 - accuracy: 0.7123 - val_loss: 0.8206 - val_accuracy: 0.6310\n",
      "Epoch 491/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6654 - accuracy: 0.7083 - val_loss: 0.8242 - val_accuracy: 0.5893\n",
      "Epoch 492/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6563 - accuracy: 0.7302 - val_loss: 0.8135 - val_accuracy: 0.6369\n",
      "Epoch 493/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6592 - accuracy: 0.7361 - val_loss: 0.8244 - val_accuracy: 0.6012\n",
      "Epoch 494/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6459 - accuracy: 0.7540 - val_loss: 0.8709 - val_accuracy: 0.6250\n",
      "Epoch 495/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6531 - accuracy: 0.7361 - val_loss: 0.8183 - val_accuracy: 0.6369\n",
      "Epoch 496/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6520 - accuracy: 0.7361 - val_loss: 0.8251 - val_accuracy: 0.6250\n",
      "Epoch 497/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6612 - accuracy: 0.7123 - val_loss: 0.8111 - val_accuracy: 0.6250\n",
      "Epoch 498/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6648 - accuracy: 0.7302 - val_loss: 0.8175 - val_accuracy: 0.6310\n",
      "Epoch 499/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6548 - accuracy: 0.7480 - val_loss: 0.8129 - val_accuracy: 0.6369\n",
      "Epoch 500/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6197 - accuracy: 0.7599 - val_loss: 0.8123 - val_accuracy: 0.6488\n",
      "Epoch 501/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6572 - accuracy: 0.7302 - val_loss: 0.8108 - val_accuracy: 0.6250\n",
      "Epoch 502/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.6471 - accuracy: 0.7599 - val_loss: 0.8191 - val_accuracy: 0.6369\n",
      "Epoch 503/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6525 - accuracy: 0.7321 - val_loss: 0.8073 - val_accuracy: 0.6488\n",
      "Epoch 504/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6396 - accuracy: 0.7401 - val_loss: 0.8238 - val_accuracy: 0.6369\n",
      "Epoch 505/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6528 - accuracy: 0.7262 - val_loss: 0.8086 - val_accuracy: 0.6369\n",
      "Epoch 506/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6515 - accuracy: 0.7262 - val_loss: 0.8075 - val_accuracy: 0.6250\n",
      "Epoch 507/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6447 - accuracy: 0.7520 - val_loss: 0.8168 - val_accuracy: 0.6250\n",
      "Epoch 508/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6538 - accuracy: 0.7341 - val_loss: 0.8127 - val_accuracy: 0.6310\n",
      "Epoch 509/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6568 - accuracy: 0.7381 - val_loss: 0.8092 - val_accuracy: 0.6429\n",
      "Epoch 510/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6506 - accuracy: 0.7540 - val_loss: 0.8080 - val_accuracy: 0.6369\n",
      "Epoch 511/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6390 - accuracy: 0.7460 - val_loss: 0.8136 - val_accuracy: 0.6250\n",
      "Epoch 512/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6216 - accuracy: 0.7579 - val_loss: 0.8097 - val_accuracy: 0.6548\n",
      "Epoch 513/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6491 - accuracy: 0.7242 - val_loss: 0.8425 - val_accuracy: 0.5952\n",
      "Epoch 514/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6400 - accuracy: 0.7381 - val_loss: 0.8054 - val_accuracy: 0.6607\n",
      "Epoch 515/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6399 - accuracy: 0.7421 - val_loss: 0.8122 - val_accuracy: 0.6071\n",
      "Epoch 516/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6442 - accuracy: 0.7500 - val_loss: 0.8053 - val_accuracy: 0.6488\n",
      "Epoch 517/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6361 - accuracy: 0.7421 - val_loss: 0.8163 - val_accuracy: 0.6369\n",
      "Epoch 518/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6389 - accuracy: 0.7421 - val_loss: 0.8050 - val_accuracy: 0.6548\n",
      "Epoch 519/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6463 - accuracy: 0.7282 - val_loss: 0.8080 - val_accuracy: 0.6488\n",
      "Epoch 520/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6378 - accuracy: 0.7540 - val_loss: 0.8146 - val_accuracy: 0.6250\n",
      "Epoch 521/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6465 - accuracy: 0.7440 - val_loss: 0.8437 - val_accuracy: 0.6131\n",
      "Epoch 522/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6561 - accuracy: 0.7440 - val_loss: 0.8134 - val_accuracy: 0.6488\n",
      "Epoch 523/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6175 - accuracy: 0.7599 - val_loss: 0.8090 - val_accuracy: 0.6429\n",
      "Epoch 524/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6330 - accuracy: 0.7758 - val_loss: 0.8213 - val_accuracy: 0.6429\n",
      "Epoch 525/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6255 - accuracy: 0.7500 - val_loss: 0.8048 - val_accuracy: 0.6369\n",
      "Epoch 526/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6315 - accuracy: 0.7520 - val_loss: 0.8086 - val_accuracy: 0.6429\n",
      "Epoch 527/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6381 - accuracy: 0.7341 - val_loss: 0.8098 - val_accuracy: 0.6250\n",
      "Epoch 528/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6213 - accuracy: 0.7599 - val_loss: 0.8007 - val_accuracy: 0.6429\n",
      "Epoch 529/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6375 - accuracy: 0.7480 - val_loss: 0.8197 - val_accuracy: 0.6190\n",
      "Epoch 530/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6401 - accuracy: 0.7560 - val_loss: 0.8047 - val_accuracy: 0.6607\n",
      "Epoch 531/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6306 - accuracy: 0.7619 - val_loss: 0.8023 - val_accuracy: 0.6369\n",
      "Epoch 532/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6417 - accuracy: 0.7341 - val_loss: 0.8232 - val_accuracy: 0.6131\n",
      "Epoch 533/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6317 - accuracy: 0.7361 - val_loss: 0.8131 - val_accuracy: 0.6310\n",
      "Epoch 534/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6085 - accuracy: 0.7639 - val_loss: 0.8019 - val_accuracy: 0.6429\n",
      "Epoch 535/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6250 - accuracy: 0.7440 - val_loss: 0.7994 - val_accuracy: 0.6429\n",
      "Epoch 536/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6166 - accuracy: 0.7520 - val_loss: 0.8116 - val_accuracy: 0.6369\n",
      "Epoch 537/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6335 - accuracy: 0.7619 - val_loss: 0.8260 - val_accuracy: 0.6250\n",
      "Epoch 538/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6341 - accuracy: 0.7381 - val_loss: 0.8090 - val_accuracy: 0.6429\n",
      "Epoch 539/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6243 - accuracy: 0.7679 - val_loss: 0.7991 - val_accuracy: 0.6429\n",
      "Epoch 540/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6404 - accuracy: 0.7500 - val_loss: 0.7997 - val_accuracy: 0.6488\n",
      "Epoch 541/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6342 - accuracy: 0.7341 - val_loss: 0.8007 - val_accuracy: 0.6369\n",
      "Epoch 542/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6271 - accuracy: 0.7500 - val_loss: 0.8081 - val_accuracy: 0.6429\n",
      "Epoch 543/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6441 - accuracy: 0.7381 - val_loss: 0.8201 - val_accuracy: 0.6310\n",
      "Epoch 544/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6242 - accuracy: 0.7659 - val_loss: 0.8053 - val_accuracy: 0.6488\n",
      "Epoch 545/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6342 - accuracy: 0.7262 - val_loss: 0.7965 - val_accuracy: 0.6607\n",
      "Epoch 546/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6429 - accuracy: 0.7341 - val_loss: 0.8019 - val_accuracy: 0.6488\n",
      "Epoch 547/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6293 - accuracy: 0.7500 - val_loss: 0.8099 - val_accuracy: 0.6429\n",
      "Epoch 548/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6243 - accuracy: 0.7500 - val_loss: 0.8075 - val_accuracy: 0.6429\n",
      "Epoch 549/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6282 - accuracy: 0.7401 - val_loss: 0.8056 - val_accuracy: 0.6369\n",
      "Epoch 550/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6128 - accuracy: 0.7579 - val_loss: 0.7978 - val_accuracy: 0.6369\n",
      "Epoch 551/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6206 - accuracy: 0.7480 - val_loss: 0.8023 - val_accuracy: 0.6429\n",
      "Epoch 552/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6216 - accuracy: 0.7560 - val_loss: 0.8066 - val_accuracy: 0.6369\n",
      "Epoch 553/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6034 - accuracy: 0.7718 - val_loss: 0.7986 - val_accuracy: 0.6607\n",
      "Epoch 554/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6135 - accuracy: 0.7579 - val_loss: 0.8162 - val_accuracy: 0.6548\n",
      "Epoch 555/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6247 - accuracy: 0.7480 - val_loss: 0.8118 - val_accuracy: 0.6369\n",
      "Epoch 556/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6282 - accuracy: 0.7500 - val_loss: 0.7997 - val_accuracy: 0.6667\n",
      "Epoch 557/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6255 - accuracy: 0.7321 - val_loss: 0.7995 - val_accuracy: 0.6369\n",
      "Epoch 558/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6190 - accuracy: 0.7520 - val_loss: 0.7955 - val_accuracy: 0.6548\n",
      "Epoch 559/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6161 - accuracy: 0.7619 - val_loss: 0.8054 - val_accuracy: 0.6488\n",
      "Epoch 560/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5917 - accuracy: 0.7619 - val_loss: 0.8037 - val_accuracy: 0.6488\n",
      "Epoch 561/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6089 - accuracy: 0.7540 - val_loss: 0.7966 - val_accuracy: 0.6429\n",
      "Epoch 562/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6076 - accuracy: 0.7440 - val_loss: 0.8038 - val_accuracy: 0.6548\n",
      "Epoch 563/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6258 - accuracy: 0.7440 - val_loss: 0.7993 - val_accuracy: 0.6310\n",
      "Epoch 564/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6187 - accuracy: 0.7480 - val_loss: 0.7982 - val_accuracy: 0.6548\n",
      "Epoch 565/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6092 - accuracy: 0.7659 - val_loss: 0.7993 - val_accuracy: 0.6548\n",
      "Epoch 566/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6166 - accuracy: 0.7500 - val_loss: 0.8120 - val_accuracy: 0.6548\n",
      "Epoch 567/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6125 - accuracy: 0.7718 - val_loss: 0.8108 - val_accuracy: 0.6429\n",
      "Epoch 568/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6149 - accuracy: 0.7500 - val_loss: 0.8163 - val_accuracy: 0.6429\n",
      "Epoch 569/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6041 - accuracy: 0.7520 - val_loss: 0.8013 - val_accuracy: 0.6369\n",
      "Epoch 570/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6116 - accuracy: 0.7540 - val_loss: 0.8002 - val_accuracy: 0.6607\n",
      "Epoch 571/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6072 - accuracy: 0.7857 - val_loss: 0.8081 - val_accuracy: 0.6488\n",
      "Epoch 572/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6182 - accuracy: 0.7758 - val_loss: 0.8107 - val_accuracy: 0.6548\n",
      "Epoch 573/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6051 - accuracy: 0.7500 - val_loss: 0.7981 - val_accuracy: 0.6548\n",
      "Epoch 574/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6275 - accuracy: 0.7520 - val_loss: 0.7961 - val_accuracy: 0.6369\n",
      "Epoch 575/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6287 - accuracy: 0.7599 - val_loss: 0.8073 - val_accuracy: 0.6548\n",
      "Epoch 576/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5991 - accuracy: 0.7758 - val_loss: 0.7974 - val_accuracy: 0.6488\n",
      "Epoch 577/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6187 - accuracy: 0.7639 - val_loss: 0.8002 - val_accuracy: 0.6488\n",
      "Epoch 578/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5944 - accuracy: 0.7619 - val_loss: 0.7976 - val_accuracy: 0.6488\n",
      "Epoch 579/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6154 - accuracy: 0.7401 - val_loss: 0.7960 - val_accuracy: 0.6667\n",
      "Epoch 580/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6069 - accuracy: 0.7718 - val_loss: 0.8022 - val_accuracy: 0.6548\n",
      "Epoch 581/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6121 - accuracy: 0.7698 - val_loss: 0.7941 - val_accuracy: 0.6548\n",
      "Epoch 582/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6126 - accuracy: 0.7440 - val_loss: 0.7983 - val_accuracy: 0.6607\n",
      "Epoch 583/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5814 - accuracy: 0.7857 - val_loss: 0.8064 - val_accuracy: 0.6369\n",
      "Epoch 584/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6090 - accuracy: 0.7659 - val_loss: 0.8004 - val_accuracy: 0.6429\n",
      "Epoch 585/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5835 - accuracy: 0.7520 - val_loss: 0.7961 - val_accuracy: 0.6607\n",
      "Epoch 586/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6034 - accuracy: 0.7440 - val_loss: 0.7914 - val_accuracy: 0.6548\n",
      "Epoch 587/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5901 - accuracy: 0.7698 - val_loss: 0.8041 - val_accuracy: 0.6310\n",
      "Epoch 588/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5951 - accuracy: 0.7718 - val_loss: 0.7934 - val_accuracy: 0.6488\n",
      "Epoch 589/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5902 - accuracy: 0.7679 - val_loss: 0.8012 - val_accuracy: 0.6429\n",
      "Epoch 590/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5851 - accuracy: 0.7698 - val_loss: 0.7937 - val_accuracy: 0.6548\n",
      "Epoch 591/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6238 - accuracy: 0.7500 - val_loss: 0.7995 - val_accuracy: 0.6369\n",
      "Epoch 592/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5980 - accuracy: 0.7619 - val_loss: 0.7966 - val_accuracy: 0.6488\n",
      "Epoch 593/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5984 - accuracy: 0.7718 - val_loss: 0.7979 - val_accuracy: 0.6607\n",
      "Epoch 594/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5811 - accuracy: 0.7976 - val_loss: 0.7965 - val_accuracy: 0.6429\n",
      "Epoch 595/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5878 - accuracy: 0.7778 - val_loss: 0.8039 - val_accuracy: 0.6190\n",
      "Epoch 596/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5861 - accuracy: 0.7778 - val_loss: 0.8002 - val_accuracy: 0.6548\n",
      "Epoch 597/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.6058 - accuracy: 0.7579 - val_loss: 0.8027 - val_accuracy: 0.6548\n",
      "Epoch 598/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6017 - accuracy: 0.7540 - val_loss: 0.7920 - val_accuracy: 0.6488\n",
      "Epoch 599/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6015 - accuracy: 0.7718 - val_loss: 0.7968 - val_accuracy: 0.6369\n",
      "Epoch 600/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5750 - accuracy: 0.7659 - val_loss: 0.7982 - val_accuracy: 0.6310\n",
      "Epoch 601/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5823 - accuracy: 0.7758 - val_loss: 0.7952 - val_accuracy: 0.6488\n",
      "Epoch 602/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5970 - accuracy: 0.7560 - val_loss: 0.7909 - val_accuracy: 0.6667\n",
      "Epoch 603/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5825 - accuracy: 0.7877 - val_loss: 0.7949 - val_accuracy: 0.6488\n",
      "Epoch 604/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5931 - accuracy: 0.7460 - val_loss: 0.8001 - val_accuracy: 0.6488\n",
      "Epoch 605/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5851 - accuracy: 0.7698 - val_loss: 0.7974 - val_accuracy: 0.6607\n",
      "Epoch 606/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5944 - accuracy: 0.7798 - val_loss: 0.7988 - val_accuracy: 0.6548\n",
      "Epoch 607/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6115 - accuracy: 0.7679 - val_loss: 0.7981 - val_accuracy: 0.6369\n",
      "Epoch 608/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5762 - accuracy: 0.7837 - val_loss: 0.7933 - val_accuracy: 0.6548\n",
      "Epoch 609/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5592 - accuracy: 0.7857 - val_loss: 0.7883 - val_accuracy: 0.6548\n",
      "Epoch 610/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5728 - accuracy: 0.7817 - val_loss: 0.7960 - val_accuracy: 0.6369\n",
      "Epoch 611/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5877 - accuracy: 0.7778 - val_loss: 0.7990 - val_accuracy: 0.6429\n",
      "Epoch 612/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5778 - accuracy: 0.7817 - val_loss: 0.7926 - val_accuracy: 0.6607\n",
      "Epoch 613/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5941 - accuracy: 0.7619 - val_loss: 0.7872 - val_accuracy: 0.6667\n",
      "Epoch 614/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5992 - accuracy: 0.7659 - val_loss: 0.7961 - val_accuracy: 0.6369\n",
      "Epoch 615/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5955 - accuracy: 0.7460 - val_loss: 0.7910 - val_accuracy: 0.6369\n",
      "Epoch 616/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5727 - accuracy: 0.7798 - val_loss: 0.7857 - val_accuracy: 0.6667\n",
      "Epoch 617/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5971 - accuracy: 0.7698 - val_loss: 0.7921 - val_accuracy: 0.6429\n",
      "Epoch 618/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5943 - accuracy: 0.7599 - val_loss: 0.8051 - val_accuracy: 0.6310\n",
      "Epoch 619/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5814 - accuracy: 0.7917 - val_loss: 0.7804 - val_accuracy: 0.6667\n",
      "Epoch 620/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5793 - accuracy: 0.7738 - val_loss: 0.8111 - val_accuracy: 0.6429\n",
      "Epoch 621/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5628 - accuracy: 0.7758 - val_loss: 0.7829 - val_accuracy: 0.6607\n",
      "Epoch 622/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5882 - accuracy: 0.7738 - val_loss: 0.7905 - val_accuracy: 0.6607\n",
      "Epoch 623/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5790 - accuracy: 0.7698 - val_loss: 0.7928 - val_accuracy: 0.6310\n",
      "Epoch 624/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.5907 - accuracy: 0.7738 - val_loss: 0.7839 - val_accuracy: 0.6607\n",
      "Epoch 625/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5783 - accuracy: 0.7917 - val_loss: 0.8072 - val_accuracy: 0.6310\n",
      "Epoch 626/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5885 - accuracy: 0.7738 - val_loss: 0.8068 - val_accuracy: 0.6250\n",
      "Epoch 627/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5611 - accuracy: 0.7897 - val_loss: 0.7872 - val_accuracy: 0.6667\n",
      "Epoch 628/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5670 - accuracy: 0.7937 - val_loss: 0.7912 - val_accuracy: 0.6429\n",
      "Epoch 629/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5714 - accuracy: 0.7679 - val_loss: 0.7856 - val_accuracy: 0.6369\n",
      "Epoch 630/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5608 - accuracy: 0.7956 - val_loss: 0.7824 - val_accuracy: 0.6488\n",
      "Epoch 631/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5717 - accuracy: 0.7718 - val_loss: 0.7957 - val_accuracy: 0.6488\n",
      "Epoch 632/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5866 - accuracy: 0.7738 - val_loss: 0.7827 - val_accuracy: 0.6667\n",
      "Epoch 633/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5665 - accuracy: 0.7917 - val_loss: 0.7785 - val_accuracy: 0.6667\n",
      "Epoch 634/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5897 - accuracy: 0.7718 - val_loss: 0.8107 - val_accuracy: 0.6131\n",
      "Epoch 635/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5700 - accuracy: 0.7937 - val_loss: 0.7780 - val_accuracy: 0.6667\n",
      "Epoch 636/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5663 - accuracy: 0.7857 - val_loss: 0.7861 - val_accuracy: 0.6548\n",
      "Epoch 637/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5612 - accuracy: 0.7817 - val_loss: 0.8128 - val_accuracy: 0.6190\n",
      "Epoch 638/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5780 - accuracy: 0.7837 - val_loss: 0.7811 - val_accuracy: 0.6667\n",
      "Epoch 639/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5726 - accuracy: 0.7679 - val_loss: 0.7843 - val_accuracy: 0.6488\n",
      "Epoch 640/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5458 - accuracy: 0.7937 - val_loss: 0.7892 - val_accuracy: 0.6607\n",
      "Epoch 641/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5893 - accuracy: 0.7401 - val_loss: 0.7799 - val_accuracy: 0.6548\n",
      "Epoch 642/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5722 - accuracy: 0.7937 - val_loss: 0.7880 - val_accuracy: 0.6310\n",
      "Epoch 643/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5719 - accuracy: 0.7758 - val_loss: 0.7847 - val_accuracy: 0.6607\n",
      "Epoch 644/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5705 - accuracy: 0.7956 - val_loss: 0.7844 - val_accuracy: 0.6667\n",
      "Epoch 645/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5877 - accuracy: 0.7698 - val_loss: 0.7947 - val_accuracy: 0.6667\n",
      "Epoch 646/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5496 - accuracy: 0.8155 - val_loss: 0.7798 - val_accuracy: 0.6548\n",
      "Epoch 647/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5791 - accuracy: 0.7639 - val_loss: 0.8014 - val_accuracy: 0.6250\n",
      "Epoch 648/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5614 - accuracy: 0.7758 - val_loss: 0.7795 - val_accuracy: 0.6667\n",
      "Epoch 649/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5825 - accuracy: 0.7698 - val_loss: 0.7907 - val_accuracy: 0.6607\n",
      "Epoch 650/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5612 - accuracy: 0.79 - 0s 18ms/step - loss: 0.5718 - accuracy: 0.7837 - val_loss: 0.7808 - val_accuracy: 0.6667\n",
      "Epoch 651/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5590 - accuracy: 0.7837 - val_loss: 0.7870 - val_accuracy: 0.6310\n",
      "Epoch 652/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5824 - accuracy: 0.7837 - val_loss: 0.7814 - val_accuracy: 0.6607\n",
      "Epoch 653/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5669 - accuracy: 0.7857 - val_loss: 0.7897 - val_accuracy: 0.6250\n",
      "Epoch 654/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5561 - accuracy: 0.7758 - val_loss: 0.7890 - val_accuracy: 0.6667\n",
      "Epoch 655/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5671 - accuracy: 0.7857 - val_loss: 0.7866 - val_accuracy: 0.6786\n",
      "Epoch 656/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5498 - accuracy: 0.7917 - val_loss: 0.7825 - val_accuracy: 0.6607\n",
      "Epoch 657/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5793 - accuracy: 0.7718 - val_loss: 0.7903 - val_accuracy: 0.6429\n",
      "Epoch 658/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5658 - accuracy: 0.7897 - val_loss: 0.7828 - val_accuracy: 0.6488\n",
      "Epoch 659/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5712 - accuracy: 0.7917 - val_loss: 0.7727 - val_accuracy: 0.6548\n",
      "Epoch 660/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5527 - accuracy: 0.7758 - val_loss: 0.7785 - val_accuracy: 0.6667\n",
      "Epoch 661/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5607 - accuracy: 0.7778 - val_loss: 0.7713 - val_accuracy: 0.6548\n",
      "Epoch 662/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5701 - accuracy: 0.7837 - val_loss: 0.7741 - val_accuracy: 0.6607\n",
      "Epoch 663/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.5464 - accuracy: 0.8016 - val_loss: 0.7796 - val_accuracy: 0.6667\n",
      "Epoch 664/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5640 - accuracy: 0.7996 - val_loss: 0.7693 - val_accuracy: 0.6548\n",
      "Epoch 665/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5436 - accuracy: 0.8016 - val_loss: 0.7755 - val_accuracy: 0.6488\n",
      "Epoch 666/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5692 - accuracy: 0.7718 - val_loss: 0.7834 - val_accuracy: 0.6548\n",
      "Epoch 667/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5675 - accuracy: 0.7897 - val_loss: 0.7857 - val_accuracy: 0.6667\n",
      "Epoch 668/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5631 - accuracy: 0.7917 - val_loss: 0.7731 - val_accuracy: 0.6548\n",
      "Epoch 669/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5561 - accuracy: 0.7857 - val_loss: 0.7951 - val_accuracy: 0.6607\n",
      "Epoch 670/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5426 - accuracy: 0.7917 - val_loss: 0.7828 - val_accuracy: 0.6607\n",
      "Epoch 671/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5591 - accuracy: 0.7857 - val_loss: 0.7738 - val_accuracy: 0.6726\n",
      "Epoch 672/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5478 - accuracy: 0.7937 - val_loss: 0.7795 - val_accuracy: 0.6726\n",
      "Epoch 673/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5429 - accuracy: 0.7897 - val_loss: 0.7798 - val_accuracy: 0.6786\n",
      "Epoch 674/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5404 - accuracy: 0.8115 - val_loss: 0.7973 - val_accuracy: 0.6429\n",
      "Epoch 675/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5408 - accuracy: 0.7937 - val_loss: 0.7751 - val_accuracy: 0.6726\n",
      "Epoch 676/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5592 - accuracy: 0.7817 - val_loss: 0.7801 - val_accuracy: 0.6488\n",
      "Epoch 677/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5476 - accuracy: 0.7817 - val_loss: 0.7725 - val_accuracy: 0.6667\n",
      "Epoch 678/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5428 - accuracy: 0.7738 - val_loss: 0.7773 - val_accuracy: 0.6548\n",
      "Epoch 679/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5447 - accuracy: 0.7877 - val_loss: 0.7748 - val_accuracy: 0.6429\n",
      "Epoch 680/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5323 - accuracy: 0.8016 - val_loss: 0.7728 - val_accuracy: 0.6488\n",
      "Epoch 681/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5709 - accuracy: 0.7679 - val_loss: 0.7704 - val_accuracy: 0.6726\n",
      "Epoch 682/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5286 - accuracy: 0.7897 - val_loss: 0.7786 - val_accuracy: 0.6667\n",
      "Epoch 683/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5535 - accuracy: 0.7996 - val_loss: 0.7712 - val_accuracy: 0.6667\n",
      "Epoch 684/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5378 - accuracy: 0.7877 - val_loss: 0.7774 - val_accuracy: 0.6667\n",
      "Epoch 685/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5250 - accuracy: 0.7897 - val_loss: 0.7700 - val_accuracy: 0.6488\n",
      "Epoch 686/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5498 - accuracy: 0.77 - 0s 15ms/step - loss: 0.5301 - accuracy: 0.7917 - val_loss: 0.7700 - val_accuracy: 0.6607\n",
      "Epoch 687/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5509 - accuracy: 0.7837 - val_loss: 0.7766 - val_accuracy: 0.6726\n",
      "Epoch 688/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5252 - accuracy: 0.7857 - val_loss: 0.7680 - val_accuracy: 0.6726\n",
      "Epoch 689/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5431 - accuracy: 0.7857 - val_loss: 0.7685 - val_accuracy: 0.6607\n",
      "Epoch 690/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5333 - accuracy: 0.8115 - val_loss: 0.7746 - val_accuracy: 0.6429\n",
      "Epoch 691/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5263 - accuracy: 0.7897 - val_loss: 0.7722 - val_accuracy: 0.6786\n",
      "Epoch 692/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5546 - accuracy: 0.7917 - val_loss: 0.7661 - val_accuracy: 0.6607\n",
      "Epoch 693/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5463 - accuracy: 0.8056 - val_loss: 0.7744 - val_accuracy: 0.6310\n",
      "Epoch 694/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5559 - accuracy: 0.7877 - val_loss: 0.7682 - val_accuracy: 0.6429\n",
      "Epoch 695/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5514 - accuracy: 0.7778 - val_loss: 0.7801 - val_accuracy: 0.6607\n",
      "Epoch 696/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5509 - accuracy: 0.8075 - val_loss: 0.7816 - val_accuracy: 0.6429\n",
      "Epoch 697/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5411 - accuracy: 0.8036 - val_loss: 0.7727 - val_accuracy: 0.6667\n",
      "Epoch 698/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5364 - accuracy: 0.8016 - val_loss: 0.7762 - val_accuracy: 0.6250\n",
      "Epoch 699/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5357 - accuracy: 0.8056 - val_loss: 0.7676 - val_accuracy: 0.6548\n",
      "Epoch 700/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5104 - accuracy: 0.8036 - val_loss: 0.7818 - val_accuracy: 0.6250\n",
      "Epoch 701/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5330 - accuracy: 0.7996 - val_loss: 0.7693 - val_accuracy: 0.6667\n",
      "Epoch 702/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5302 - accuracy: 0.7956 - val_loss: 0.7707 - val_accuracy: 0.6607\n",
      "Epoch 703/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5266 - accuracy: 0.7877 - val_loss: 0.7811 - val_accuracy: 0.6429\n",
      "Epoch 704/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5300 - accuracy: 0.8016 - val_loss: 0.7656 - val_accuracy: 0.6607\n",
      "Epoch 705/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5468 - accuracy: 0.7956 - val_loss: 0.7693 - val_accuracy: 0.6607\n",
      "Epoch 706/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5135 - accuracy: 0.8155 - val_loss: 0.7842 - val_accuracy: 0.6310\n",
      "Epoch 707/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5311 - accuracy: 0.8175 - val_loss: 0.7708 - val_accuracy: 0.6667\n",
      "Epoch 708/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5370 - accuracy: 0.7996 - val_loss: 0.7756 - val_accuracy: 0.6607\n",
      "Epoch 709/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5334 - accuracy: 0.7817 - val_loss: 0.7670 - val_accuracy: 0.6726\n",
      "Epoch 710/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5183 - accuracy: 0.8115 - val_loss: 0.7691 - val_accuracy: 0.6667\n",
      "Epoch 711/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5238 - accuracy: 0.8135 - val_loss: 0.7783 - val_accuracy: 0.6726\n",
      "Epoch 712/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.5590 - accuracy: 0.7758 - val_loss: 0.7730 - val_accuracy: 0.6548\n",
      "Epoch 713/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5207 - accuracy: 0.7956 - val_loss: 0.7864 - val_accuracy: 0.6190\n",
      "Epoch 714/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5475 - accuracy: 0.7897 - val_loss: 0.7654 - val_accuracy: 0.6548\n",
      "Epoch 715/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5196 - accuracy: 0.8175 - val_loss: 0.7684 - val_accuracy: 0.6607\n",
      "Epoch 716/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.5353 - accuracy: 0.8095 - val_loss: 0.7692 - val_accuracy: 0.6488\n",
      "Epoch 717/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5336 - accuracy: 0.7937 - val_loss: 0.7701 - val_accuracy: 0.6607\n",
      "Epoch 718/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5426 - accuracy: 0.7778 - val_loss: 0.7694 - val_accuracy: 0.6488\n",
      "Epoch 719/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5474 - accuracy: 0.7877 - val_loss: 0.7703 - val_accuracy: 0.6667\n",
      "Epoch 720/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5307 - accuracy: 0.8234 - val_loss: 0.7733 - val_accuracy: 0.6845\n",
      "Epoch 721/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5356 - accuracy: 0.8115 - val_loss: 0.7714 - val_accuracy: 0.6667\n",
      "Epoch 722/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5092 - accuracy: 0.7996 - val_loss: 0.7719 - val_accuracy: 0.6667\n",
      "Epoch 723/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5301 - accuracy: 0.8036 - val_loss: 0.7699 - val_accuracy: 0.6726\n",
      "Epoch 724/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5069 - accuracy: 0.8036 - val_loss: 0.7856 - val_accuracy: 0.6667\n",
      "Epoch 725/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.5025 - accuracy: 0.8036 - val_loss: 0.7814 - val_accuracy: 0.6726\n",
      "Epoch 726/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5327 - accuracy: 0.7976 - val_loss: 0.7842 - val_accuracy: 0.6607\n",
      "Epoch 727/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5159 - accuracy: 0.8036 - val_loss: 0.7768 - val_accuracy: 0.6607\n",
      "Epoch 728/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5177 - accuracy: 0.8056 - val_loss: 0.7731 - val_accuracy: 0.6607\n",
      "Epoch 729/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5352 - accuracy: 0.7937 - val_loss: 0.7900 - val_accuracy: 0.6726\n",
      "Epoch 730/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5061 - accuracy: 0.8075 - val_loss: 0.7776 - val_accuracy: 0.6667\n",
      "Epoch 731/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5269 - accuracy: 0.7937 - val_loss: 0.7741 - val_accuracy: 0.6667\n",
      "Epoch 732/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5191 - accuracy: 0.8056 - val_loss: 0.7810 - val_accuracy: 0.6369\n",
      "Epoch 733/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5237 - accuracy: 0.7897 - val_loss: 0.7751 - val_accuracy: 0.6667\n",
      "Epoch 734/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5191 - accuracy: 0.8175 - val_loss: 0.7694 - val_accuracy: 0.6726\n",
      "Epoch 735/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5135 - accuracy: 0.7877 - val_loss: 0.7786 - val_accuracy: 0.6607\n",
      "Epoch 736/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5115 - accuracy: 0.8056 - val_loss: 0.7746 - val_accuracy: 0.6607\n",
      "Epoch 737/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5122 - accuracy: 0.7996 - val_loss: 0.7803 - val_accuracy: 0.6548\n",
      "Epoch 738/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5291 - accuracy: 0.8175 - val_loss: 0.7691 - val_accuracy: 0.6607\n",
      "Epoch 739/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5186 - accuracy: 0.7956 - val_loss: 0.7733 - val_accuracy: 0.6607\n",
      "Epoch 740/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5124 - accuracy: 0.8194 - val_loss: 0.7689 - val_accuracy: 0.6667\n",
      "Epoch 741/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5340 - accuracy: 0.7917 - val_loss: 0.7788 - val_accuracy: 0.6726\n",
      "Epoch 742/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5207 - accuracy: 0.8175 - val_loss: 0.7666 - val_accuracy: 0.6726\n",
      "Epoch 743/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5229 - accuracy: 0.7917 - val_loss: 0.7762 - val_accuracy: 0.6786\n",
      "Epoch 744/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5161 - accuracy: 0.8095 - val_loss: 0.7809 - val_accuracy: 0.6845\n",
      "Epoch 745/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5110 - accuracy: 0.8056 - val_loss: 0.7722 - val_accuracy: 0.6726\n",
      "Epoch 746/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5090 - accuracy: 0.8115 - val_loss: 0.7654 - val_accuracy: 0.6726\n",
      "Epoch 747/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5232 - accuracy: 0.8194 - val_loss: 0.7543 - val_accuracy: 0.6548\n",
      "Epoch 748/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5105 - accuracy: 0.8056 - val_loss: 0.7626 - val_accuracy: 0.6667\n",
      "Epoch 749/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5155 - accuracy: 0.7917 - val_loss: 0.7598 - val_accuracy: 0.6429\n",
      "Epoch 750/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.5055 - accuracy: 0.8135 - val_loss: 0.7677 - val_accuracy: 0.6726\n",
      "Epoch 751/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5112 - accuracy: 0.7738 - val_loss: 0.7600 - val_accuracy: 0.6726\n",
      "Epoch 752/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5034 - accuracy: 0.7956 - val_loss: 0.7611 - val_accuracy: 0.6667\n",
      "Epoch 753/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.5138 - accuracy: 0.8016 - val_loss: 0.7591 - val_accuracy: 0.6488\n",
      "Epoch 754/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5064 - accuracy: 0.8075 - val_loss: 0.7799 - val_accuracy: 0.6607\n",
      "Epoch 755/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5138 - accuracy: 0.8155 - val_loss: 0.7587 - val_accuracy: 0.6845\n",
      "Epoch 756/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4996 - accuracy: 0.8234 - val_loss: 0.7806 - val_accuracy: 0.6667\n",
      "Epoch 757/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5212 - accuracy: 0.7937 - val_loss: 0.7564 - val_accuracy: 0.6786\n",
      "Epoch 758/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5026 - accuracy: 0.8115 - val_loss: 0.7682 - val_accuracy: 0.6667\n",
      "Epoch 759/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5233 - accuracy: 0.7996 - val_loss: 0.7684 - val_accuracy: 0.6667\n",
      "Epoch 760/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5172 - accuracy: 0.8016 - val_loss: 0.7591 - val_accuracy: 0.6667\n",
      "Epoch 761/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4873 - accuracy: 0.8274 - val_loss: 0.7627 - val_accuracy: 0.6667\n",
      "Epoch 762/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5053 - accuracy: 0.8234 - val_loss: 0.7851 - val_accuracy: 0.6726\n",
      "Epoch 763/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5089 - accuracy: 0.8075 - val_loss: 0.7759 - val_accuracy: 0.6726\n",
      "Epoch 764/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4926 - accuracy: 0.8274 - val_loss: 0.7728 - val_accuracy: 0.6845\n",
      "Epoch 765/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5054 - accuracy: 0.8115 - val_loss: 0.7660 - val_accuracy: 0.6786\n",
      "Epoch 766/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4937 - accuracy: 0.8234 - val_loss: 0.7723 - val_accuracy: 0.6845\n",
      "Epoch 767/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5062 - accuracy: 0.8016 - val_loss: 0.7793 - val_accuracy: 0.6667\n",
      "Epoch 768/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5241 - accuracy: 0.7976 - val_loss: 0.7642 - val_accuracy: 0.6667\n",
      "Epoch 769/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5045 - accuracy: 0.8036 - val_loss: 0.7730 - val_accuracy: 0.6607\n",
      "Epoch 770/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.5006 - accuracy: 0.8135 - val_loss: 0.7690 - val_accuracy: 0.6667\n",
      "Epoch 771/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.5017 - accuracy: 0.8095 - val_loss: 0.7644 - val_accuracy: 0.6786\n",
      "Epoch 772/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4752 - accuracy: 0.8393 - val_loss: 0.7742 - val_accuracy: 0.6786\n",
      "Epoch 773/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4872 - accuracy: 0.8274 - val_loss: 0.7683 - val_accuracy: 0.6726\n",
      "Epoch 774/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4907 - accuracy: 0.8095 - val_loss: 0.7637 - val_accuracy: 0.6667\n",
      "Epoch 775/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4951 - accuracy: 0.8155 - val_loss: 0.7814 - val_accuracy: 0.6905\n",
      "Epoch 776/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5044 - accuracy: 0.7996 - val_loss: 0.7605 - val_accuracy: 0.6786\n",
      "Epoch 777/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4750 - accuracy: 0.8115 - val_loss: 0.7586 - val_accuracy: 0.6607\n",
      "Epoch 778/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4968 - accuracy: 0.8135 - val_loss: 0.7871 - val_accuracy: 0.6845\n",
      "Epoch 779/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5013 - accuracy: 0.7917 - val_loss: 0.7594 - val_accuracy: 0.6429\n",
      "Epoch 780/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4903 - accuracy: 0.8333 - val_loss: 0.7518 - val_accuracy: 0.6726\n",
      "Epoch 781/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5110 - accuracy: 0.8075 - val_loss: 0.7545 - val_accuracy: 0.6607\n",
      "Epoch 782/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4784 - accuracy: 0.8135 - val_loss: 0.7539 - val_accuracy: 0.6845\n",
      "Epoch 783/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4609 - accuracy: 0.8373 - val_loss: 0.7651 - val_accuracy: 0.6667\n",
      "Epoch 784/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4829 - accuracy: 0.8294 - val_loss: 0.7610 - val_accuracy: 0.6786\n",
      "Epoch 785/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5124 - accuracy: 0.7956 - val_loss: 0.7548 - val_accuracy: 0.6548\n",
      "Epoch 786/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5143 - accuracy: 0.7877 - val_loss: 0.7501 - val_accuracy: 0.6667\n",
      "Epoch 787/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5029 - accuracy: 0.8155 - val_loss: 0.7789 - val_accuracy: 0.6786\n",
      "Epoch 788/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 0.4836 - accuracy: 0.82 - 0s 14ms/step - loss: 0.4836 - accuracy: 0.8274 - val_loss: 0.7456 - val_accuracy: 0.6607\n",
      "Epoch 789/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4813 - accuracy: 0.8155 - val_loss: 0.7491 - val_accuracy: 0.6607\n",
      "Epoch 790/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4826 - accuracy: 0.8155 - val_loss: 0.7583 - val_accuracy: 0.6786\n",
      "Epoch 791/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4881 - accuracy: 0.8155 - val_loss: 0.7528 - val_accuracy: 0.6607\n",
      "Epoch 792/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5070 - accuracy: 0.8016 - val_loss: 0.7643 - val_accuracy: 0.6667\n",
      "Epoch 793/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4970 - accuracy: 0.8214 - val_loss: 0.7550 - val_accuracy: 0.6905\n",
      "Epoch 794/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4751 - accuracy: 0.8155 - val_loss: 0.7457 - val_accuracy: 0.6607\n",
      "Epoch 795/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4898 - accuracy: 0.8056 - val_loss: 0.7586 - val_accuracy: 0.6845\n",
      "Epoch 796/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4918 - accuracy: 0.8135 - val_loss: 0.7497 - val_accuracy: 0.6726\n",
      "Epoch 797/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4909 - accuracy: 0.8452 - val_loss: 0.7515 - val_accuracy: 0.6488\n",
      "Epoch 798/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5040 - accuracy: 0.8254 - val_loss: 0.7467 - val_accuracy: 0.6726\n",
      "Epoch 799/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4822 - accuracy: 0.8234 - val_loss: 0.7494 - val_accuracy: 0.6488\n",
      "Epoch 800/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.4649 - accuracy: 0.8393 - val_loss: 0.7432 - val_accuracy: 0.6667\n",
      "Epoch 801/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4866 - accuracy: 0.8433 - val_loss: 0.7541 - val_accuracy: 0.6667\n",
      "Epoch 802/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4819 - accuracy: 0.8175 - val_loss: 0.7580 - val_accuracy: 0.6786\n",
      "Epoch 803/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4917 - accuracy: 0.8175 - val_loss: 0.7516 - val_accuracy: 0.6369\n",
      "Epoch 804/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4919 - accuracy: 0.8313 - val_loss: 0.7453 - val_accuracy: 0.6429\n",
      "Epoch 805/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4994 - accuracy: 0.7917 - val_loss: 0.7519 - val_accuracy: 0.6548\n",
      "Epoch 806/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4716 - accuracy: 0.8254 - val_loss: 0.7464 - val_accuracy: 0.6786\n",
      "Epoch 807/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4890 - accuracy: 0.7996 - val_loss: 0.7484 - val_accuracy: 0.6369\n",
      "Epoch 808/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4777 - accuracy: 0.8313 - val_loss: 0.7436 - val_accuracy: 0.6667\n",
      "Epoch 809/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4812 - accuracy: 0.8175 - val_loss: 0.7512 - val_accuracy: 0.6607\n",
      "Epoch 810/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.4963 - accuracy: 0.8175 - val_loss: 0.7569 - val_accuracy: 0.6786\n",
      "Epoch 811/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4847 - accuracy: 0.8115 - val_loss: 0.7556 - val_accuracy: 0.6667\n",
      "Epoch 812/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4899 - accuracy: 0.8155 - val_loss: 0.7642 - val_accuracy: 0.6905\n",
      "Epoch 813/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.4640 - accuracy: 0.8313 - val_loss: 0.7655 - val_accuracy: 0.6845\n",
      "Epoch 814/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4737 - accuracy: 0.82 - 0s 26ms/step - loss: 0.4737 - accuracy: 0.8234 - val_loss: 0.7586 - val_accuracy: 0.6726\n",
      "Epoch 815/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4751 - accuracy: 0.8115 - val_loss: 0.7520 - val_accuracy: 0.6786\n",
      "Epoch 816/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4683 - accuracy: 0.8353 - val_loss: 0.7525 - val_accuracy: 0.6429\n",
      "Epoch 817/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4816 - accuracy: 0.8413 - val_loss: 0.7553 - val_accuracy: 0.6726\n",
      "Epoch 818/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4654 - accuracy: 0.8333 - val_loss: 0.7630 - val_accuracy: 0.6667\n",
      "Epoch 819/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4790 - accuracy: 0.8214 - val_loss: 0.7503 - val_accuracy: 0.6667\n",
      "Epoch 820/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4876 - accuracy: 0.8175 - val_loss: 0.7657 - val_accuracy: 0.6726\n",
      "Epoch 821/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.4750 - accuracy: 0.8175 - val_loss: 0.7448 - val_accuracy: 0.6607\n",
      "Epoch 822/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4682 - accuracy: 0.8472 - val_loss: 0.7410 - val_accuracy: 0.6786\n",
      "Epoch 823/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4537 - accuracy: 0.8313 - val_loss: 0.7509 - val_accuracy: 0.6488\n",
      "Epoch 824/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.4812 - accuracy: 0.8175 - val_loss: 0.7505 - val_accuracy: 0.6667\n",
      "Epoch 825/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.4539 - accuracy: 0.8492 - val_loss: 0.7704 - val_accuracy: 0.6607\n",
      "Epoch 826/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4554 - accuracy: 0.8433 - val_loss: 0.7567 - val_accuracy: 0.6667\n",
      "Epoch 827/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4777 - accuracy: 0.8135 - val_loss: 0.7565 - val_accuracy: 0.6369\n",
      "Epoch 828/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4691 - accuracy: 0.8433 - val_loss: 0.7559 - val_accuracy: 0.6429\n",
      "Epoch 829/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4659 - accuracy: 0.8413 - val_loss: 0.7576 - val_accuracy: 0.6667\n",
      "Epoch 830/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4656 - accuracy: 0.8194 - val_loss: 0.7554 - val_accuracy: 0.6845\n",
      "Epoch 831/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4613 - accuracy: 0.8155 - val_loss: 0.7600 - val_accuracy: 0.6369\n",
      "Epoch 832/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.4667 - accuracy: 0.8313 - val_loss: 0.7566 - val_accuracy: 0.6786\n",
      "Epoch 833/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4747 - accuracy: 0.8333 - val_loss: 0.7476 - val_accuracy: 0.6726\n",
      "Epoch 834/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4724 - accuracy: 0.8155 - val_loss: 0.7565 - val_accuracy: 0.6786\n",
      "Epoch 835/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4868 - accuracy: 0.8155 - val_loss: 0.7454 - val_accuracy: 0.6786\n",
      "Epoch 836/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4529 - accuracy: 0.8492 - val_loss: 0.7549 - val_accuracy: 0.6845\n",
      "Epoch 837/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4695 - accuracy: 0.8294 - val_loss: 0.7515 - val_accuracy: 0.6786\n",
      "Epoch 838/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4634 - accuracy: 0.8373 - val_loss: 0.7538 - val_accuracy: 0.6845\n",
      "Epoch 839/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4615 - accuracy: 0.8413 - val_loss: 0.7579 - val_accuracy: 0.6845\n",
      "Epoch 840/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4646 - accuracy: 0.8333 - val_loss: 0.7624 - val_accuracy: 0.6845\n",
      "Epoch 841/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4736 - accuracy: 0.8175 - val_loss: 0.7593 - val_accuracy: 0.6786\n",
      "Epoch 842/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4721 - accuracy: 0.8214 - val_loss: 0.7643 - val_accuracy: 0.6726\n",
      "Epoch 843/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4535 - accuracy: 0.8413 - val_loss: 0.7672 - val_accuracy: 0.6726\n",
      "Epoch 844/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4631 - accuracy: 0.8333 - val_loss: 0.7529 - val_accuracy: 0.6845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 845/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4550 - accuracy: 0.8532 - val_loss: 0.7469 - val_accuracy: 0.6726\n",
      "Epoch 846/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4758 - accuracy: 0.8373 - val_loss: 0.7461 - val_accuracy: 0.6667\n",
      "Epoch 847/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4477 - accuracy: 0.8492 - val_loss: 0.7545 - val_accuracy: 0.6845\n",
      "Epoch 848/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4482 - accuracy: 0.8313 - val_loss: 0.7545 - val_accuracy: 0.6845\n",
      "Epoch 849/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4473 - accuracy: 0.8433 - val_loss: 0.7573 - val_accuracy: 0.6488\n",
      "Epoch 850/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4527 - accuracy: 0.8313 - val_loss: 0.7515 - val_accuracy: 0.6786\n",
      "Epoch 851/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4387 - accuracy: 0.8452 - val_loss: 0.7507 - val_accuracy: 0.6964\n",
      "Epoch 852/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4635 - accuracy: 0.8353 - val_loss: 0.7643 - val_accuracy: 0.6667\n",
      "Epoch 853/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4743 - accuracy: 0.8155 - val_loss: 0.7465 - val_accuracy: 0.6786\n",
      "Epoch 854/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4732 - accuracy: 0.8274 - val_loss: 0.7550 - val_accuracy: 0.6905\n",
      "Epoch 855/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4627 - accuracy: 0.8294 - val_loss: 0.7512 - val_accuracy: 0.6845\n",
      "Epoch 856/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4627 - accuracy: 0.8353 - val_loss: 0.7470 - val_accuracy: 0.6786\n",
      "Epoch 857/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4697 - accuracy: 0.8373 - val_loss: 0.7436 - val_accuracy: 0.6667\n",
      "Epoch 858/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4455 - accuracy: 0.8393 - val_loss: 0.7602 - val_accuracy: 0.6905\n",
      "Epoch 859/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4475 - accuracy: 0.8492 - val_loss: 0.7414 - val_accuracy: 0.6845\n",
      "Epoch 860/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4578 - accuracy: 0.8214 - val_loss: 0.7430 - val_accuracy: 0.6667\n",
      "Epoch 861/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4544 - accuracy: 0.8194 - val_loss: 0.7476 - val_accuracy: 0.6488\n",
      "Epoch 862/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4451 - accuracy: 0.8214 - val_loss: 0.7445 - val_accuracy: 0.6786\n",
      "Epoch 863/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4752 - accuracy: 0.8155 - val_loss: 0.7362 - val_accuracy: 0.6667\n",
      "Epoch 864/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4492 - accuracy: 0.8393 - val_loss: 0.7718 - val_accuracy: 0.6786\n",
      "Epoch 865/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4577 - accuracy: 0.8234 - val_loss: 0.7384 - val_accuracy: 0.6786\n",
      "Epoch 866/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4699 - accuracy: 0.8313 - val_loss: 0.7393 - val_accuracy: 0.6726\n",
      "Epoch 867/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4656 - accuracy: 0.8393 - val_loss: 0.7429 - val_accuracy: 0.6845\n",
      "Epoch 868/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4475 - accuracy: 0.8313 - val_loss: 0.7515 - val_accuracy: 0.6964\n",
      "Epoch 869/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4761 - accuracy: 0.8274 - val_loss: 0.7459 - val_accuracy: 0.6905\n",
      "Epoch 870/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4595 - accuracy: 0.8393 - val_loss: 0.7428 - val_accuracy: 0.6488\n",
      "Epoch 871/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4328 - accuracy: 0.8433 - val_loss: 0.7539 - val_accuracy: 0.6845\n",
      "Epoch 872/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4479 - accuracy: 0.8373 - val_loss: 0.7546 - val_accuracy: 0.6667\n",
      "Epoch 873/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4556 - accuracy: 0.8175 - val_loss: 0.7493 - val_accuracy: 0.6786\n",
      "Epoch 874/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4590 - accuracy: 0.8194 - val_loss: 0.7504 - val_accuracy: 0.6905\n",
      "Epoch 875/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4505 - accuracy: 0.8333 - val_loss: 0.7458 - val_accuracy: 0.6845\n",
      "Epoch 876/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4388 - accuracy: 0.8333 - val_loss: 0.7452 - val_accuracy: 0.6905\n",
      "Epoch 877/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4648 - accuracy: 0.8194 - val_loss: 0.7395 - val_accuracy: 0.6726\n",
      "Epoch 878/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4561 - accuracy: 0.8393 - val_loss: 0.7423 - val_accuracy: 0.6488\n",
      "Epoch 879/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4449 - accuracy: 0.8353 - val_loss: 0.7476 - val_accuracy: 0.6607\n",
      "Epoch 880/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4672 - accuracy: 0.8254 - val_loss: 0.7506 - val_accuracy: 0.6726\n",
      "Epoch 881/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4594 - accuracy: 0.8333 - val_loss: 0.7481 - val_accuracy: 0.6905\n",
      "Epoch 882/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4603 - accuracy: 0.8472 - val_loss: 0.7369 - val_accuracy: 0.6845\n",
      "Epoch 883/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4428 - accuracy: 0.8452 - val_loss: 0.7450 - val_accuracy: 0.6845\n",
      "Epoch 884/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4450 - accuracy: 0.8413 - val_loss: 0.7431 - val_accuracy: 0.6905\n",
      "Epoch 885/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4442 - accuracy: 0.8274 - val_loss: 0.7420 - val_accuracy: 0.6667\n",
      "Epoch 886/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4458 - accuracy: 0.8433 - val_loss: 0.7399 - val_accuracy: 0.6905\n",
      "Epoch 887/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4455 - accuracy: 0.8472 - val_loss: 0.7434 - val_accuracy: 0.6905\n",
      "Epoch 888/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4447 - accuracy: 0.8353 - val_loss: 0.7417 - val_accuracy: 0.6845\n",
      "Epoch 889/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4367 - accuracy: 0.8492 - val_loss: 0.7492 - val_accuracy: 0.6964\n",
      "Epoch 890/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4366 - accuracy: 0.8373 - val_loss: 0.7438 - val_accuracy: 0.6905\n",
      "Epoch 891/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4555 - accuracy: 0.8254 - val_loss: 0.7449 - val_accuracy: 0.6964\n",
      "Epoch 892/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4324 - accuracy: 0.8373 - val_loss: 0.7321 - val_accuracy: 0.6786\n",
      "Epoch 893/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4401 - accuracy: 0.8472 - val_loss: 0.7402 - val_accuracy: 0.6726\n",
      "Epoch 894/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4442 - accuracy: 0.8353 - val_loss: 0.7477 - val_accuracy: 0.6607\n",
      "Epoch 895/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4404 - accuracy: 0.8512 - val_loss: 0.7363 - val_accuracy: 0.6845\n",
      "Epoch 896/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4314 - accuracy: 0.8611 - val_loss: 0.7366 - val_accuracy: 0.6905\n",
      "Epoch 897/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4292 - accuracy: 0.8492 - val_loss: 0.7583 - val_accuracy: 0.6845\n",
      "Epoch 898/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4231 - accuracy: 0.8552 - val_loss: 0.7296 - val_accuracy: 0.6786\n",
      "Epoch 899/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4187 - accuracy: 0.8532 - val_loss: 0.7318 - val_accuracy: 0.6845\n",
      "Epoch 900/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4476 - accuracy: 0.8313 - val_loss: 0.7312 - val_accuracy: 0.6667\n",
      "Epoch 901/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4314 - accuracy: 0.8393 - val_loss: 0.7410 - val_accuracy: 0.6905\n",
      "Epoch 902/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4142 - accuracy: 0.8532 - val_loss: 0.7267 - val_accuracy: 0.6905\n",
      "Epoch 903/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4238 - accuracy: 0.8651 - val_loss: 0.7366 - val_accuracy: 0.6905\n",
      "Epoch 904/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4415 - accuracy: 0.8433 - val_loss: 0.7332 - val_accuracy: 0.6726\n",
      "Epoch 905/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4139 - accuracy: 0.8651 - val_loss: 0.7249 - val_accuracy: 0.6726\n",
      "Epoch 906/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4319 - accuracy: 0.8274 - val_loss: 0.7531 - val_accuracy: 0.6905\n",
      "Epoch 907/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4380 - accuracy: 0.8472 - val_loss: 0.7434 - val_accuracy: 0.6726\n",
      "Epoch 908/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4360 - accuracy: 0.8333 - val_loss: 0.7383 - val_accuracy: 0.6667\n",
      "Epoch 909/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4482 - accuracy: 0.8274 - val_loss: 0.7429 - val_accuracy: 0.6845\n",
      "Epoch 910/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4185 - accuracy: 0.8472 - val_loss: 0.7400 - val_accuracy: 0.6905\n",
      "Epoch 911/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4137 - accuracy: 0.8492 - val_loss: 0.7370 - val_accuracy: 0.6845\n",
      "Epoch 912/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4053 - accuracy: 0.8512 - val_loss: 0.7308 - val_accuracy: 0.6905\n",
      "Epoch 913/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4210 - accuracy: 0.8611 - val_loss: 0.7611 - val_accuracy: 0.6964\n",
      "Epoch 914/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4585 - accuracy: 0.8274 - val_loss: 0.7323 - val_accuracy: 0.6845\n",
      "Epoch 915/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4426 - accuracy: 0.8274 - val_loss: 0.7352 - val_accuracy: 0.6667\n",
      "Epoch 916/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4398 - accuracy: 0.8373 - val_loss: 0.7356 - val_accuracy: 0.6845\n",
      "Epoch 917/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4220 - accuracy: 0.8472 - val_loss: 0.7420 - val_accuracy: 0.6964\n",
      "Epoch 918/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4393 - accuracy: 0.8373 - val_loss: 0.7381 - val_accuracy: 0.6905\n",
      "Epoch 919/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4463 - accuracy: 0.8254 - val_loss: 0.7368 - val_accuracy: 0.6845\n",
      "Epoch 920/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4191 - accuracy: 0.8472 - val_loss: 0.7406 - val_accuracy: 0.6786\n",
      "Epoch 921/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4366 - accuracy: 0.8333 - val_loss: 0.7355 - val_accuracy: 0.6964\n",
      "Epoch 922/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4382 - accuracy: 0.8393 - val_loss: 0.7288 - val_accuracy: 0.6726\n",
      "Epoch 923/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4234 - accuracy: 0.8512 - val_loss: 0.7429 - val_accuracy: 0.6845\n",
      "Epoch 924/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4289 - accuracy: 0.8393 - val_loss: 0.7276 - val_accuracy: 0.6845\n",
      "Epoch 925/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4099 - accuracy: 0.8671 - val_loss: 0.7205 - val_accuracy: 0.6964\n",
      "Epoch 926/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4022 - accuracy: 0.8492 - val_loss: 0.7336 - val_accuracy: 0.6726\n",
      "Epoch 927/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4230 - accuracy: 0.8571 - val_loss: 0.7217 - val_accuracy: 0.6964\n",
      "Epoch 928/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4220 - accuracy: 0.8373 - val_loss: 0.7370 - val_accuracy: 0.6786\n",
      "Epoch 929/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4349 - accuracy: 0.8452 - val_loss: 0.7303 - val_accuracy: 0.6905\n",
      "Epoch 930/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4038 - accuracy: 0.8552 - val_loss: 0.7293 - val_accuracy: 0.6845\n",
      "Epoch 931/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4301 - accuracy: 0.8433 - val_loss: 0.7296 - val_accuracy: 0.6905\n",
      "Epoch 932/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4064 - accuracy: 0.84 - 0s 15ms/step - loss: 0.4146 - accuracy: 0.8452 - val_loss: 0.7382 - val_accuracy: 0.6726\n",
      "Epoch 933/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4206 - accuracy: 0.8631 - val_loss: 0.7284 - val_accuracy: 0.6667\n",
      "Epoch 934/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4363 - accuracy: 0.8452 - val_loss: 0.7286 - val_accuracy: 0.6905\n",
      "Epoch 935/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4436 - accuracy: 0.8155 - val_loss: 0.7624 - val_accuracy: 0.6845\n",
      "Epoch 936/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4239 - accuracy: 0.8512 - val_loss: 0.7192 - val_accuracy: 0.6845\n",
      "Epoch 937/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4265 - accuracy: 0.8651 - val_loss: 0.7239 - val_accuracy: 0.6905\n",
      "Epoch 938/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4319 - accuracy: 0.8413 - val_loss: 0.7229 - val_accuracy: 0.6964\n",
      "Epoch 939/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4255 - accuracy: 0.8353 - val_loss: 0.7183 - val_accuracy: 0.6905\n",
      "Epoch 940/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4126 - accuracy: 0.8651 - val_loss: 0.7189 - val_accuracy: 0.6905\n",
      "Epoch 941/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4153 - accuracy: 0.8532 - val_loss: 0.7201 - val_accuracy: 0.6964\n",
      "Epoch 942/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4030 - accuracy: 0.8591 - val_loss: 0.7256 - val_accuracy: 0.6845\n",
      "Epoch 943/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4068 - accuracy: 0.8472 - val_loss: 0.7270 - val_accuracy: 0.6845\n",
      "Epoch 944/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4253 - accuracy: 0.8393 - val_loss: 0.7245 - val_accuracy: 0.6905\n",
      "Epoch 945/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3987 - accuracy: 0.8710 - val_loss: 0.7257 - val_accuracy: 0.6726\n",
      "Epoch 946/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4110 - accuracy: 0.8631 - val_loss: 0.7297 - val_accuracy: 0.7024\n",
      "Epoch 947/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4251 - accuracy: 0.8234 - val_loss: 0.7254 - val_accuracy: 0.6964\n",
      "Epoch 948/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4334 - accuracy: 0.8512 - val_loss: 0.7322 - val_accuracy: 0.6964\n",
      "Epoch 949/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4374 - accuracy: 0.8353 - val_loss: 0.7341 - val_accuracy: 0.6786\n",
      "Epoch 950/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4212 - accuracy: 0.8512 - val_loss: 0.7252 - val_accuracy: 0.7024\n",
      "Epoch 951/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4131 - accuracy: 0.8472 - val_loss: 0.7248 - val_accuracy: 0.6786\n",
      "Epoch 952/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4092 - accuracy: 0.8591 - val_loss: 0.7305 - val_accuracy: 0.6905\n",
      "Epoch 953/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4223 - accuracy: 0.8472 - val_loss: 0.7222 - val_accuracy: 0.7024\n",
      "Epoch 954/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4106 - accuracy: 0.8651 - val_loss: 0.7273 - val_accuracy: 0.6786\n",
      "Epoch 955/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4048 - accuracy: 0.8571 - val_loss: 0.7473 - val_accuracy: 0.6786\n",
      "Epoch 956/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3971 - accuracy: 0.8690 - val_loss: 0.7287 - val_accuracy: 0.6905\n",
      "Epoch 957/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4044 - accuracy: 0.8532 - val_loss: 0.7477 - val_accuracy: 0.6905\n",
      "Epoch 958/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4011 - accuracy: 0.8671 - val_loss: 0.7300 - val_accuracy: 0.6845\n",
      "Epoch 959/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4239 - accuracy: 0.8333 - val_loss: 0.7197 - val_accuracy: 0.6964\n",
      "Epoch 960/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3919 - accuracy: 0.8750 - val_loss: 0.7291 - val_accuracy: 0.6845\n",
      "Epoch 961/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4084 - accuracy: 0.8611 - val_loss: 0.7235 - val_accuracy: 0.6667\n",
      "Epoch 962/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4016 - accuracy: 0.8552 - val_loss: 0.7255 - val_accuracy: 0.6845\n",
      "Epoch 963/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4229 - accuracy: 0.8452 - val_loss: 0.7204 - val_accuracy: 0.6726\n",
      "Epoch 964/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4100 - accuracy: 0.8512 - val_loss: 0.7287 - val_accuracy: 0.6845\n",
      "Epoch 965/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3992 - accuracy: 0.8571 - val_loss: 0.7346 - val_accuracy: 0.6786\n",
      "Epoch 966/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3926 - accuracy: 0.8611 - val_loss: 0.7245 - val_accuracy: 0.6845\n",
      "Epoch 967/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4191 - accuracy: 0.8452 - val_loss: 0.7430 - val_accuracy: 0.6845\n",
      "Epoch 968/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4246 - accuracy: 0.8353 - val_loss: 0.7280 - val_accuracy: 0.6964\n",
      "Epoch 969/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3902 - accuracy: 0.8571 - val_loss: 0.7292 - val_accuracy: 0.6845\n",
      "Epoch 970/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4136 - accuracy: 0.8552 - val_loss: 0.7296 - val_accuracy: 0.6964\n",
      "Epoch 971/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3877 - accuracy: 0.8730 - val_loss: 0.7237 - val_accuracy: 0.7024\n",
      "Epoch 972/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3974 - accuracy: 0.8591 - val_loss: 0.7383 - val_accuracy: 0.7083\n",
      "Epoch 973/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3906 - accuracy: 0.8710 - val_loss: 0.7451 - val_accuracy: 0.6964\n",
      "Epoch 974/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.3856 - accuracy: 0.8690 - val_loss: 0.7365 - val_accuracy: 0.6964\n",
      "Epoch 975/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3981 - accuracy: 0.8452 - val_loss: 0.7329 - val_accuracy: 0.6905\n",
      "Epoch 976/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3929 - accuracy: 0.8651 - val_loss: 0.7432 - val_accuracy: 0.6548\n",
      "Epoch 977/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4395 - accuracy: 0.8373 - val_loss: 0.7242 - val_accuracy: 0.6786\n",
      "Epoch 978/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4082 - accuracy: 0.8472 - val_loss: 0.7231 - val_accuracy: 0.6786\n",
      "Epoch 979/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3898 - accuracy: 0.8750 - val_loss: 0.7283 - val_accuracy: 0.6607\n",
      "Epoch 980/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3990 - accuracy: 0.8690 - val_loss: 0.7231 - val_accuracy: 0.6845\n",
      "Epoch 981/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3864 - accuracy: 0.8611 - val_loss: 0.7261 - val_accuracy: 0.6726\n",
      "Epoch 982/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3893 - accuracy: 0.8591 - val_loss: 0.7266 - val_accuracy: 0.6845\n",
      "Epoch 983/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3768 - accuracy: 0.8730 - val_loss: 0.7339 - val_accuracy: 0.6964\n",
      "Epoch 984/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4004 - accuracy: 0.8571 - val_loss: 0.7415 - val_accuracy: 0.7024\n",
      "Epoch 985/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4266 - accuracy: 0.8472 - val_loss: 0.7435 - val_accuracy: 0.6726\n",
      "Epoch 986/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3968 - accuracy: 0.8631 - val_loss: 0.7207 - val_accuracy: 0.6667\n",
      "Epoch 987/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3836 - accuracy: 0.8770 - val_loss: 0.7218 - val_accuracy: 0.6845\n",
      "Epoch 988/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3754 - accuracy: 0.8750 - val_loss: 0.7548 - val_accuracy: 0.6905\n",
      "Epoch 989/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4035 - accuracy: 0.8571 - val_loss: 0.7271 - val_accuracy: 0.6845\n",
      "Epoch 990/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3826 - accuracy: 0.8730 - val_loss: 0.7269 - val_accuracy: 0.6964\n",
      "Epoch 991/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3869 - accuracy: 0.8750 - val_loss: 0.7272 - val_accuracy: 0.6905\n",
      "Epoch 992/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3891 - accuracy: 0.8631 - val_loss: 0.7258 - val_accuracy: 0.6905\n",
      "Epoch 993/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4012 - accuracy: 0.8651 - val_loss: 0.7374 - val_accuracy: 0.6964\n",
      "Epoch 994/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3936 - accuracy: 0.8591 - val_loss: 0.7244 - val_accuracy: 0.6964\n",
      "Epoch 995/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4101 - accuracy: 0.8492 - val_loss: 0.7165 - val_accuracy: 0.6964\n",
      "Epoch 996/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3885 - accuracy: 0.8651 - val_loss: 0.7265 - val_accuracy: 0.6845\n",
      "Epoch 997/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3771 - accuracy: 0.8750 - val_loss: 0.7308 - val_accuracy: 0.6667\n",
      "Epoch 998/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3771 - accuracy: 0.8909 - val_loss: 0.7248 - val_accuracy: 0.6905\n",
      "Epoch 999/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3989 - accuracy: 0.8512 - val_loss: 0.7427 - val_accuracy: 0.7024\n",
      "Epoch 1000/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3905 - accuracy: 0.8730 - val_loss: 0.7203 - val_accuracy: 0.6845\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',\n",
    "                 input_shape=(168,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "opt = optimizers.RMSprop(learning_rate=0.00005, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=64, epochs=1000, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ca11f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_name = \"D:\\\\gitProjects\\\\ids-project\\\\data\\\\e_to_the_pi_i_for_dummies_v240P_segments\\\\audio\"\n",
    "folder = os.fsencode(folder_name)\n",
    "df_emotions = pd.DataFrame(columns=['file_name', 'emotion', 'start_time', 'emotion_class', 'confidence'])\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    file_name = os.fsdecode(file)\n",
    "    path = folder_name + \"\\\\\" + file_name\n",
    "    \n",
    "    features = extract_feature(path, mfcc=True, mel=True)\n",
    "    features = np.expand_dims(features, axis=1)\n",
    "    features = np.expand_dims(features, axis=0)\n",
    "    features = features.astype(np.float32)\n",
    "    \n",
    "    start_time = file_name.split('_')[-3]\n",
    "    \n",
    "    predic = model.predict(features)\n",
    "    predic_confidence = float(np.amax(predic,1)[0])\n",
    "\n",
    "    emotion = category_to_emotion[np.argmax(predic)]\n",
    "    emotion_class = emotions_dict[emotion]\n",
    "    new_row = {'file_name': file_name,\n",
    "               'emotion': emotion,\n",
    "              'start_time': int(start_time),\n",
    "              'emotion_class': emotion_class,\n",
    "              'confidence': predic_confidence}\n",
    "    df_emotions = df_emotions.append(new_row, ignore_index=True)\n",
    "\n",
    "df_emotions.sort_values(by='start_time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "f2c8e149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (16,12))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(np.array(df_emotions['emotion']), 'b.')\n",
    "plt.subplot(2,1,2)\n",
    "df_emotions['emotion'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "05153718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>emotion</th>\n",
       "      <th>start_time</th>\n",
       "      <th>emotion_class</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e_to_the_pi_i_for_dummies_v240P_0_3_audio.wav</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>e_to_the_pi_i_for_dummies_v240P_3_6_audio.wav</td>\n",
       "      <td>happy</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>e_to_the_pi_i_for_dummies_v240P_6_9_audio.wav</td>\n",
       "      <td>happy</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.709440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>e_to_the_pi_i_for_dummies_v240P_9_12_audio.wav</td>\n",
       "      <td>happy</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.918563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>e_to_the_pi_i_for_dummies_v240P_12_15_audio.wav</td>\n",
       "      <td>happy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.650562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>e_to_the_pi_i_for_dummies_v240P_579_582_audio.wav</td>\n",
       "      <td>happy</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>0.771719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>e_to_the_pi_i_for_dummies_v240P_582_585_audio.wav</td>\n",
       "      <td>happy</td>\n",
       "      <td>582</td>\n",
       "      <td>1</td>\n",
       "      <td>0.819926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>e_to_the_pi_i_for_dummies_v240P_585_588_audio.wav</td>\n",
       "      <td>happy</td>\n",
       "      <td>585</td>\n",
       "      <td>1</td>\n",
       "      <td>0.918161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>e_to_the_pi_i_for_dummies_v240P_591_594_audio.wav</td>\n",
       "      <td>happy</td>\n",
       "      <td>591</td>\n",
       "      <td>1</td>\n",
       "      <td>0.752411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>e_to_the_pi_i_for_dummies_v240P_594_597_audio.wav</td>\n",
       "      <td>happy</td>\n",
       "      <td>594</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             file_name emotion start_time  \\\n",
       "0        e_to_the_pi_i_for_dummies_v240P_0_3_audio.wav   happy          0   \n",
       "111      e_to_the_pi_i_for_dummies_v240P_3_6_audio.wav   happy          3   \n",
       "188      e_to_the_pi_i_for_dummies_v240P_6_9_audio.wav   happy          6   \n",
       "199     e_to_the_pi_i_for_dummies_v240P_9_12_audio.wav   happy          9   \n",
       "11     e_to_the_pi_i_for_dummies_v240P_12_15_audio.wav   happy         12   \n",
       "..                                                 ...     ...        ...   \n",
       "176  e_to_the_pi_i_for_dummies_v240P_579_582_audio.wav   happy        579   \n",
       "178  e_to_the_pi_i_for_dummies_v240P_582_585_audio.wav   happy        582   \n",
       "179  e_to_the_pi_i_for_dummies_v240P_585_588_audio.wav   happy        585   \n",
       "181  e_to_the_pi_i_for_dummies_v240P_591_594_audio.wav   happy        591   \n",
       "182  e_to_the_pi_i_for_dummies_v240P_594_597_audio.wav   happy        594   \n",
       "\n",
       "    emotion_class  confidence  \n",
       "0               1    0.999986  \n",
       "111             1    0.999996  \n",
       "188             1    0.709440  \n",
       "199             1    0.918563  \n",
       "11              1    0.650562  \n",
       "..            ...         ...  \n",
       "176             1    0.771719  \n",
       "178             1    0.819926  \n",
       "179             1    0.918161  \n",
       "181             1    0.752411  \n",
       "182             1    0.969756  \n",
       "\n",
       "[161 rows x 5 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emotions.where(df_emotions['emotion']=='happy').dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e812fc0",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d680083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(model,\"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
