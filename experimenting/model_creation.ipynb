{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "351562af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile # to read audio file\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa # to extract speech features\n",
    "import glob\n",
    "import os\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcca1363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name, **kwargs):\n",
    "    \"\"\"\n",
    "    Extract feature from audio file `file_name`\n",
    "        Features supported:\n",
    "            - MFCC (mfcc)\n",
    "            - Chroma (chroma)\n",
    "            - MEL Spectrogram Frequency (mel)\n",
    "            - Contrast (contrast)\n",
    "            - Tonnetz (tonnetz)\n",
    "        e.g:\n",
    "        `features = extract_feature(path, mel=True, mfcc=True)`\n",
    "    \"\"\"\n",
    "    mfcc = kwargs.get(\"mfcc\")\n",
    "    chroma = kwargs.get(\"chroma\")\n",
    "    mel = kwargs.get(\"mel\")\n",
    "    contrast = kwargs.get(\"contrast\")\n",
    "    tonnetz = kwargs.get(\"tonnetz\")\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        if (len(X.shape) != 1):\n",
    "            return [None]\n",
    "        sample_rate = sound_file.samplerate\n",
    "        if chroma or contrast:\n",
    "            stft = np.abs(librosa.stft(X))\n",
    "        result = np.array([])\n",
    "        if mfcc:\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, mel))\n",
    "        if contrast:\n",
    "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, contrast))\n",
    "        if tonnetz:\n",
    "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, tonnetz))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2166053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## codes in data\n",
    "int2emotion = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n",
    "\n",
    "# only files with these emotion labels are used\n",
    "emotions_dict ={\n",
    "    \"angry\": 0,\n",
    "    \"sad\": 1,\n",
    "    \"neutral\": 2,\n",
    "    \"happy\": 3\n",
    "}\n",
    "\n",
    "category_to_emotion = {}\n",
    "\n",
    "for key in emotions_dict.keys():\n",
    "    value = emotions_dict[key]\n",
    "    category_to_emotion[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ce95a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(test_size=0.2, max_amount=10000):\n",
    "    i = 0\n",
    "    X, y = [], []\n",
    "    amount = 0\n",
    "    for file in glob.glob(\"ravdess/Audio*/Actor_*/*.wav\"):\n",
    "        if (amount >= max_amount):\n",
    "            break\n",
    "        \n",
    "        basename = os.path.basename(file)\n",
    "        \n",
    "        emotion = int2emotion[basename.split(\"-\")[2]]\n",
    "        allowed_emotions = emotions_dict.keys()\n",
    "        \n",
    "        if emotion not in allowed_emotions:\n",
    "            continue\n",
    "        emotion_category = emotions_dict[emotion]\n",
    "        \n",
    "        features = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        \n",
    "        ## there seems to be some unusable data so lets get rid of those\n",
    "        if (features[0] == None):\n",
    "            continue\n",
    "        \n",
    "        \n",
    "            \n",
    "        X.append(features)\n",
    "        y.append(emotion_category)\n",
    "        amount = amount + 1\n",
    "        \n",
    "    return train_test_split(np.array(X), y, test_size=test_size, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "359b4abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_amount_of_data = 10000\n",
    "X_train, X_test, y_train, y_test = load_data(test_size=0.25, max_amount=max_amount_of_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c50dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make ready for pytorch\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "\n",
    "y_train = np.asarray(y_train)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = np.asarray(y_test)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "                                          \n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "y_test = torch.from_numpy(y_test).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eae6ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Number of training samples: 503\n",
      "[+] Number of testing samples: 168\n",
      "[+] Number of features: 180\n"
     ]
    }
   ],
   "source": [
    "print(\"[+] Number of training samples:\", X_train.shape[0])\n",
    "# number of samples in testing data\n",
    "print(\"[+] Number of testing samples:\", X_test.shape[0])\n",
    "# number of features used\n",
    "# this is a vector of features extracted \n",
    "# using extract_features() function\n",
    "print(\"[+] Number of features:\", X_train.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd60587b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] X_train first value's first 5 values tensor([-694.3492,   57.4134,   -2.8856,   11.7412,   -9.1497])\n",
      "[+] y_train first value tensor(1)\n"
     ]
    }
   ],
   "source": [
    "print(\"[+] X_train first value's first 5 values\", X_train[0][0:5])\n",
    "print(\"[+] y_train first value\", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb0cf930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE = 'cpu'\n",
    "print('Using {} device'.format(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a526b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = len(emotions_dict.keys())\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=180, out_features=16)\n",
    "        self.fc2 = nn.Linear(in_features=16, out_features=12)\n",
    "        self.output = nn.Linear(in_features=12, out_features=out)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "226e7cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (fc1): Linear(in_features=180, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=12, bias=True)\n",
      "  (output): Linear(in_features=12, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(DEVICE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ba665e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 65\n",
    "EPOCHS = 10\n",
    "LR = 0.01\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c816b6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([503, 180])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5816ead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "loss_arr = []\n",
    "epoch_arr = []\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    y_hat = model.forward(X_train)\n",
    "    loss = criterion(y_hat, y_train)\n",
    "    epoch_arr.append(i)\n",
    "    \n",
    "    loss_arr.append(loss.item())\n",
    " \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0e90c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch number')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(epoch_arr, loss_arr)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19579da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model to file\n",
    "PATH = \"model.pt\"\n",
    "torch.save(model, PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0529557d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (fc1): Linear(in_features=180, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=12, bias=True)\n",
       "  (output): Linear(in_features=12, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load from file\n",
    "loaded_model = torch.load(PATH)\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dadd48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make predictions using the loaded model\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for val in X_test:\n",
    "        y_hat = loaded_model.forward(val)\n",
    "        preds.append(y_hat.argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "803079d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Y_correct': y_test, 'Y_predicted': preds})\n",
    "df['Correct'] = [1 if corr == pred else 0 for corr, pred in zip(df['Y_correct'], df['Y_predicted'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f98c828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_correct</th>\n",
       "      <th>Y_predicted</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y_correct  Y_predicted  Correct\n",
       "0          0            0        1\n",
       "1          1            1        1\n",
       "2          2            2        1\n",
       "3          0            2        0\n",
       "4          2            2        1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88f6eacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 'angry' accuracy is 0.8103448275862069\n",
      "Category 'sad' accuracy is 0.5531914893617021\n",
      "Category 'neutral' accuracy is 0.6086956521739131\n",
      "Category 'happy' accuracy is 0.75\n"
     ]
    }
   ],
   "source": [
    "for category in category_to_emotion.keys():\n",
    "    category_results = df[df['Y_correct'] == category]\n",
    "    res = category_results['Correct'].sum() / len(category_results)\n",
    "    emotion = category_to_emotion[category]\n",
    "    to_print = f\"Category '{emotion}' accuracy is {res}\"\n",
    "    print(to_print)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8ff6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
