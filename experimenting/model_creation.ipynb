{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "22932dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile # to read audio file\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa # to extract speech features\n",
    "import glob\n",
    "import os\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "549ab7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name, **kwargs):\n",
    "    \"\"\"\n",
    "    Extract feature from audio file `file_name`\n",
    "        Features supported:\n",
    "            - MFCC (mfcc)\n",
    "            - Chroma (chroma)\n",
    "            - MEL Spectrogram Frequency (mel)\n",
    "            - Contrast (contrast)\n",
    "            - Tonnetz (tonnetz)\n",
    "        e.g:\n",
    "        `features = extract_feature(path, mel=True, mfcc=True)`\n",
    "    \"\"\"\n",
    "    mfcc = kwargs.get(\"mfcc\")\n",
    "    chroma = kwargs.get(\"chroma\")\n",
    "    mel = kwargs.get(\"mel\")\n",
    "    contrast = kwargs.get(\"contrast\")\n",
    "    tonnetz = kwargs.get(\"tonnetz\")\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        if (len(X.shape) != 1):\n",
    "            return [None]\n",
    "        sample_rate = sound_file.samplerate\n",
    "        if chroma or contrast:\n",
    "            stft = np.abs(librosa.stft(X))\n",
    "        result = np.array([])\n",
    "        if mfcc:\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, mel))\n",
    "        if contrast:\n",
    "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, contrast))\n",
    "        if tonnetz:\n",
    "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, tonnetz))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "63e34d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## codes in data\n",
    "int2emotion = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n",
    "\n",
    "# only files with these emotion labels are used\n",
    "emotions_dict ={\n",
    "    \"angry\": 0,\n",
    "    \"sad\": 1,\n",
    "    \"neutral\": 2,\n",
    "    \"happy\": 3\n",
    "}\n",
    "\n",
    "category_to_emotion = {}\n",
    "\n",
    "for key in emotions_dict.keys():\n",
    "    value = emotions_dict[key]\n",
    "    category_to_emotion[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7e93c28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(test_size=0.2, max_amount=10000):\n",
    "    i = 0\n",
    "    X, y = [], []\n",
    "    amount = 0\n",
    "    for file in glob.glob(\"ravdess/Audio*/Actor_*/*.wav\"):\n",
    "        if (amount >= max_amount):\n",
    "            break\n",
    "        \n",
    "        basename = os.path.basename(file)\n",
    "        \n",
    "        emotion = int2emotion[basename.split(\"-\")[2]]\n",
    "        allowed_emotions = emotions_dict.keys()\n",
    "        \n",
    "        if emotion not in allowed_emotions:\n",
    "            continue\n",
    "        emotion_category = emotions_dict[emotion]\n",
    "        \n",
    "        features = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        \n",
    "        ## there seems to be some unusable data so lets get rid of those\n",
    "        if (features[0] == None):\n",
    "            continue\n",
    "        \n",
    "        \n",
    "            \n",
    "        X.append(features)\n",
    "        y.append(emotion_category)\n",
    "        amount = amount + 1\n",
    "        \n",
    "    return train_test_split(np.array(X), y, test_size=test_size, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7ba73665",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_amount_of_data = 100\n",
    "X_train, X_test, y_train, y_test = load_data(test_size=0.25, max_amount=max_amount_of_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b88c6c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make ready for pytorch\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "\n",
    "y_train = np.asarray(y_train)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = np.asarray(y_test)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "                                          \n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "y_test = torch.from_numpy(y_test).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b999e44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Number of training samples: 75\n",
      "[+] Number of testing samples: 25\n",
      "[+] Number of features: 180\n"
     ]
    }
   ],
   "source": [
    "print(\"[+] Number of training samples:\", X_train.shape[0])\n",
    "# number of samples in testing data\n",
    "print(\"[+] Number of testing samples:\", X_test.shape[0])\n",
    "# number of features used\n",
    "# this is a vector of features extracted \n",
    "# using extract_features() function\n",
    "print(\"[+] Number of features:\", X_train.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2be44d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] X_train first value's first 5 values tensor([-614.5449,   65.8200,  -26.8686,    3.0917,  -10.1031])\n",
      "[+] y_train first value tensor(1)\n"
     ]
    }
   ],
   "source": [
    "print(\"[+] X_train first value's first 5 values\", X_train[0][0:5])\n",
    "print(\"[+] y_train first value\", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c6e25ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c806d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = len(emotions_dict.keys())\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=180, out_features=16)\n",
    "        self.fc2 = nn.Linear(in_features=16, out_features=12)\n",
    "        self.output = nn.Linear(in_features=12, out_features=out)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4da1e5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (fc1): Linear(in_features=180, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=12, bias=True)\n",
      "  (output): Linear(in_features=12, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(DEVICE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7d4d1fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 65\n",
    "EPOCHS = 10\n",
    "LR = 0.01\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2a375ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([75, 180])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4806d271",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "loss_arr = []\n",
    "epoch_arr = []\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    y_hat = model.forward(X_train)\n",
    "    loss = criterion(y_hat, y_train)\n",
    "    epoch_arr.append(i)\n",
    "    \n",
    "    loss_arr.append(loss.item())\n",
    " \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e5536806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch number')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(epoch_arr, loss_arr)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8b074c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model to file\n",
    "PATH = \"model.pt\"\n",
    "torch.save(model, PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "defa92f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (fc1): Linear(in_features=180, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=12, bias=True)\n",
       "  (output): Linear(in_features=12, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load from file\n",
    "loaded_model = torch.load(PATH)\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2a4b94a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make predictions using the loaded model\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for val in X_test:\n",
    "        y_hat = loaded_model.forward(val)\n",
    "        preds.append(y_hat.argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "eabe17c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Y_correct': y_test, 'Y_predicted': preds})\n",
    "df['Correct'] = [1 if corr == pred else 0 for corr, pred in zip(df['Y_correct'], df['Y_predicted'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8e0a7f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_correct</th>\n",
       "      <th>Y_predicted</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y_correct  Y_predicted  Correct\n",
       "0          3            3        1\n",
       "1          0            0        1\n",
       "2          0            0        1\n",
       "3          3            3        1\n",
       "4          0            0        1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ad4c61a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 'angry' accuracy is 0.8571428571428571\n",
      "Category 'sad' accuracy is 0.875\n",
      "Category 'neutral' accuracy is 0.6666666666666666\n",
      "Category 'happy' accuracy is 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "for category in category_to_emotion.keys():\n",
    "    category_results = df[df['Y_correct'] == category]\n",
    "    res = category_results['Correct'].sum() / len(category_results)\n",
    "    emotion = category_to_emotion[category]\n",
    "    to_print = f\"Category '{emotion}' accuracy is {res}\"\n",
    "    print(to_print)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bdcd9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
